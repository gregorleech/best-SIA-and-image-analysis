{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gleech\\Documents\\GitHub\\kai codes\\best SIA\\tiff_file.py:1995: UserWarning: failed to import _tifffile.decodepackbits\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n",
      "C:\\Users\\gleech\\Documents\\GitHub\\kai codes\\best SIA\\tiff_file.py:1995: UserWarning: failed to import _tifffile.decodelzw\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n",
      "C:\\Users\\gleech\\Documents\\GitHub\\kai codes\\best SIA\\tiff_file.py:1995: UserWarning: failed to import _tifffile.unpackints\n",
      "  warnings.warn(\"failed to import %s\" % module_function)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2, fftshift\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter1d as gf1d\n",
    "from scipy.ndimage import gaussian_filter as gf\n",
    "from scipy.ndimage import uniform_filter as uf\n",
    "from skimage.transform import downscale_local_mean #For binning\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "\n",
    "import xarray as xr #package for labeling and adding metadata to multi-dimensional arrays\n",
    "\n",
    "import sys\n",
    "#sys.path.append(\"../kai_colloids/PyDDM\") #must point to the PyDDM folder\n",
    "#import ddm_analysis_and_fitting as ddm   \n",
    "\n",
    "import tiff_file \n",
    "\n",
    "import io \n",
    "import sys\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob #glob is helpful for searching for filenames or directories\n",
    "import pickle #for saving data\n",
    "### usually this block prints out \"nd2reader module not found. Reading of .nd2 files disabled.\" on the first run\n",
    "### this is fine (unless you need to read .nd2 files), just re-run this block to make the error go away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from  matplotlib.animation import FuncAnimation\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  # for convenience\n",
    "\n",
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "\n",
    "import collections\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "import yaml\n",
    "import gc\n",
    "\n",
    "import numpy as np #numerical python used for working with arrays, mathematical operations\n",
    "import xarray as xr #package for labeling and adding metadata to multi-dimensional arrays\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../kai crosslinking (phase 2)/PyDDM\") #must point to the PyDDM folder\n",
    "#import ddm_analysis_and_fitting as ddm\n",
    "from nd2reader import ND2Reader\n",
    "\n",
    "from skimage import io \n",
    "from skimage.transform import downscale_local_mean #For binning\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import glob #glob is helpful for searching for filenames or directories\n",
    "import pickle #for saving data\n",
    "\n",
    "from numpy.polynomial import Polynomial\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First define the functions we will need to use\n",
    "### The Structural Image Autocorrelation (SIA) function is the second function defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this function (newRadav) finds the radial average of the image autocorrelation in the SIA function \n",
    "def newRadav(im, limangles=False, angRange=None, mask=None, rev=False,\n",
    "             debug_q = None):\n",
    "    if mask is None:\n",
    "        hasMask = False\n",
    "    else:\n",
    "        hasMask = True\n",
    "    nx,ny = im.shape\n",
    "    xx = np.arange(-(nx-1)/2., nx/2.)\n",
    "    yy = np.arange(-(ny-1)/2., ny/2.)\n",
    "    #x,y = np.meshgrid(xx,yy)\n",
    "    x,y = np.meshgrid(yy,xx)\n",
    "    q = np.sqrt(x**2 + y**2)\n",
    "    angles = np.arctan2(x,y)\n",
    "    \n",
    "    qx = np.arange(-1*nx/2,nx/2)*(1./nx) * max(nx,ny)\n",
    "    qy = np.arange(-1*ny/2,ny/2)*(1./ny) * max(nx,ny)\n",
    "    qxx,qyy = np.meshgrid(qy,qx) #qy,qx is correct order\n",
    "    q_new = np.sqrt(qxx**2 + qyy**2)\n",
    "    \n",
    "    if debug_q is not None:\n",
    "        return q_new.round().astype(int)==debug_q\n",
    "    \n",
    "    if mask is None:\n",
    "        mask = np.ones_like(angles)\n",
    "    if angRange is not None:\n",
    "        w1 = np.where(angles>angRange[0])\n",
    "    else:\n",
    "        w1 = np.where(angles>(13*np.pi/14))\n",
    "    if mask is None:\n",
    "        mask[w1]=0\n",
    "        mask = mask * np.rot90(np.rot90(mask))\n",
    "        mask = mask * np.flipud(mask)\n",
    "        mask[np.where(mask==0)] = np.nan\n",
    "        if rev:\n",
    "            mask = np.rot90(mask)\n",
    "    qr = q_new.round().astype(int)\n",
    "    #rs = np.arange(0,(nx-1)/2)\n",
    "    rs = np.arange(0,(max(nx,ny)-1)/2) \n",
    "    radav = np.zeros((len(rs)),dtype=float)\n",
    "    for i in range(0,len(rs)):\n",
    "        w = np.where(qr==rs[i])\n",
    "        if len(w[0])>0:\n",
    "            if limangles or hasMask:\n",
    "                newim = im*mask\n",
    "                radav[i] = np.nanmean(newim[w])\n",
    "            else:\n",
    "                radav[i] = np.nanmean(im[w])\n",
    "        #else:\n",
    "        #    print i\n",
    "    return radav\n",
    "\n",
    "def zerolistmaker(n):\n",
    "    listofzeros = ['none found'] * n\n",
    "    return listofzeros\n",
    "\n",
    "def threshold_images(image, block_size, offset_val):\n",
    "    ed_image = (image**0.2)*500\n",
    "    ed_thresh = threshold_local(ed_image, block_size, offset= offset_val)\n",
    "    ed_binary_im = 1*(ed_image > ed_thresh)\n",
    "    #binned_ed_binary_im = downscale_local_mean(ed_binary_im, (2,2), cval=1)\n",
    "    #print(binned_ed_binary_im.shape)\n",
    "    #return binned_ed_binary_im\n",
    "    return ed_binary_im\n",
    "\n",
    "### the SIA function \n",
    "def SIA(image, block_size, offset_val):\n",
    "    ''' Computes image autocorrelation. \n",
    "    Takes as input:\n",
    "        image: 2D image\n",
    "        filter: Boolean, if true will filter image with uniform filter\n",
    "        filtersize: size for uniform filtering\n",
    "    Returns:\n",
    "        corr_im: the image autocorrelation (this will be same size as image)\n",
    "        rav_corr: radially averaged image autocorrelation '''\n",
    "    \n",
    "    ### Crop image\n",
    "    #image = image[:1440, :1440]    ###option to crop out any large noise features \n",
    "\n",
    "    image = threshold_images(image, block_size, offset_val)\n",
    "    \n",
    "    image = 1.0*image-image.mean() #subtract mean\n",
    "    image = image/image.std() #normalize by standard deviation\n",
    "    corr_im = np.real(fftshift(ifft2(fft2(image)*np.conj(fft2(image)))))/(image.shape[0]*image.shape[1])\n",
    "    \n",
    "    ### radial average taken\n",
    "    rav_corr = newRadav(corr_im)\n",
    "    \n",
    "    ### return ONLY rav_corr **b/c I don't need corr_im** (change this if you do need corr_im) \n",
    "    return rav_corr\n",
    "\n",
    "###define the single exponential we use to fit SIA curves\n",
    "str_equation = False\n",
    "def single_exponential(x, A, cl):\n",
    "    #return (np.exp(-x/cl) + A) \n",
    "    if str_equation == True:\n",
    "        return \"(1-A)*exp(-x/cl) + A\"\n",
    "    else:\n",
    "        return (1-A)*(np.exp(-x/cl)) + A\n",
    "    \n",
    "### the following functions ('show_threshold_images', and 'show_filtered_images') are used to preview \n",
    "### the images intended for analysis\n",
    "def show_raw_images(row, ax, i, frame_key):\n",
    "    plt.gray()\n",
    "    index_add = arr_length * (row -1)\n",
    "    if time_array[i] == 0:\n",
    "        test_image = np.zeros((1440,1920))\n",
    "        ax.set_title('[no image]', fontsize=10)\n",
    "    else:\n",
    "        test_image = tiff_file.imread(files[i+index_add],key=[frame_key])\n",
    "        ax.set_title(\"~\" + str(time_array[i]) + \" hrs (row\"+str(row)+\")\", fontsize=10)\n",
    "    ax.imshow(test_image) #cmap = 'gray'\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout(pad=.2)\n",
    "    \n",
    "def show_threshold_images(row, ax, i, frame_key, block_size, offset_val):\n",
    "    index_add = arr_length * (row -1)\n",
    "    if time_array[i] == 0:\n",
    "        threshold_image = np.zeros((1440,1920))\n",
    "        ax.set_title('[no image]', fontsize=10)\n",
    "    else:\n",
    "        raw_image = tiff_file.imread(files[i+index_add],key=[frame_key])\n",
    "        ax.set_title(\"~\" + str(time_array[i]) + \" hrs (row\"+str(row)+\") --> threshold\", fontsize=10)\n",
    "        threshold_image = threshold_images(raw_image, block_size, offset_val)\n",
    "    ax.imshow(threshold_image, cmap = 'gray')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout(pad=.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate your data (tiff files) and choose where to save results     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 \t half-x_s1_t1_row1.tif\n",
      " 1 \t half-x_s1_t1_row2.tif\n",
      " 2 \t half-x_s1_t1_row3.tif\n",
      " 3 \t half-x_s1_t1_row4.tif\n",
      " 4 \t half-x_s1_t1_row5.tif\n",
      " 5 \t half-x_s1_t1_row6.tif\n",
      " 6 \t half-x_s1_t2_row1.tif\n",
      " 7 \t half-x_s1_t2_row2.tif\n",
      " 8 \t half-x_s1_t2_row3.tif\n",
      " 9 \t half-x_s1_t2_row4.tif\n",
      " 10 \t half-x_s1_t2_row5.tif\n",
      " 11 \t half-x_s1_t2_row6.tif\n",
      " 12 \t half-x_s1_t3_row1.tif\n",
      " 13 \t half-x_s1_t3_row2.tif\n",
      " 14 \t half-x_s1_t3_row3.tif\n",
      " 15 \t half-x_s1_t3_row4.tif\n",
      " 16 \t half-x_s1_t3_row5.tif\n",
      " 17 \t half-x_s1_t3_row6.tif\n",
      " 18 \t half-x_s1_t4_row1.tif\n",
      " 19 \t half-x_s1_t4_row2.tif\n",
      " 20 \t half-x_s1_t4_row3.tif\n",
      " 21 \t half-x_s1_t4_row4.tif\n",
      " 22 \t half-x_s1_t4_row5.tif\n",
      " 23 \t half-x_s1_t4_row6.tif\n",
      " 24 \t half-x_s1_t5_row1.tif\n",
      " 25 \t half-x_s1_t5_row2.tif\n",
      " 26 \t half-x_s1_t5_row3.tif\n",
      " 27 \t half-x_s1_t5_row4.tif\n",
      " 28 \t half-x_s1_t5_row5.tif\n",
      " 29 \t half-x_s1_t5_row6.tif\n",
      " 30 \t half-x_s1_t6_row1.tif\n",
      " 31 \t half-x_s1_t6_row2.tif\n",
      " 32 \t half-x_s1_t6_row3.tif\n",
      " 33 \t half-x_s1_t6_row4.tif\n",
      " 34 \t half-x_s1_t6_row5.tif\n",
      " 35 \t half-x_s1_t6_row6.tif\n",
      " 36 \t half-x_s1_t7_row1.tif\n",
      " 37 \t half-x_s1_t7_row2.tif\n",
      " 38 \t half-x_s1_t7_row3.tif\n",
      " 39 \t half-x_s1_t7_row4.tif\n",
      " 40 \t half-x_s1_t7_row5.tif\n",
      " 41 \t half-x_s1_t7_row6.tif\n",
      " 42 \t half-x_s1_t8_row1.tif\n",
      " 43 \t half-x_s1_t8_row2.tif\n",
      " 44 \t half-x_s1_t8_row3.tif\n",
      " 45 \t half-x_s1_t8_row4.tif\n",
      " 46 \t half-x_s1_t8_row5.tif\n",
      " 47 \t half-x_s1_t8_row6.tif\n",
      " 48 \t half-x_s2_t1_row1.tif\n",
      " 49 \t half-x_s2_t1_row2.tif\n",
      " 50 \t half-x_s2_t1_row3.tif\n",
      " 51 \t half-x_s2_t1_row4.tif\n",
      " 52 \t half-x_s2_t1_row5.tif\n",
      " 53 \t half-x_s2_t1_row6.tif\n",
      " 54 \t half-x_s2_t2_row1.tif\n",
      " 55 \t half-x_s2_t2_row2.tif\n",
      " 56 \t half-x_s2_t2_row3.tif\n",
      " 57 \t half-x_s2_t2_row4.tif\n",
      " 58 \t half-x_s2_t2_row5.tif\n",
      " 59 \t half-x_s2_t2_row6.tif\n",
      " 60 \t half-x_s2_t3_row1.tif\n",
      " 61 \t half-x_s2_t3_row2.tif\n",
      " 62 \t half-x_s2_t3_row3.tif\n",
      " 63 \t half-x_s2_t3_row4.tif\n",
      " 64 \t half-x_s2_t3_row5.tif\n",
      " 65 \t half-x_s2_t3_row6.tif\n",
      " 66 \t half-x_s2_t4_row1.tif\n",
      " 67 \t half-x_s2_t4_row2.tif\n",
      " 68 \t half-x_s2_t4_row3.tif\n",
      " 69 \t half-x_s2_t4_row4.tif\n",
      " 70 \t half-x_s2_t4_row5.tif\n",
      " 71 \t half-x_s2_t4_row6.tif\n",
      " 72 \t half-x_s2_t5_row1.tif\n",
      " 73 \t half-x_s2_t5_row2.tif\n",
      " 74 \t half-x_s2_t5_row3.tif\n",
      " 75 \t half-x_s2_t5_row4.tif\n",
      " 76 \t half-x_s2_t5_row5.tif\n",
      " 77 \t half-x_s2_t5_row6.tif\n",
      " 78 \t half-x_s2_t6_row1.tif\n",
      " 79 \t half-x_s2_t6_row2.tif\n",
      " 80 \t half-x_s2_t6_row3.tif\n",
      " 81 \t half-x_s2_t6_row4.tif\n",
      " 82 \t half-x_s2_t6_row5.tif\n",
      " 83 \t half-x_s2_t6_row6.tif\n",
      " 84 \t half-x_s2_t7_row1.tif\n",
      " 85 \t half-x_s2_t7_row2.tif\n",
      " 86 \t half-x_s2_t7_row3.tif\n",
      " 87 \t half-x_s2_t7_row4.tif\n",
      " 88 \t half-x_s2_t7_row5.tif\n",
      " 89 \t half-x_s2_t7_row6.tif\n",
      " 90 \t half-x_s2_t8_row1.tif\n",
      " 91 \t half-x_s2_t8_row2.tif\n",
      " 92 \t half-x_s2_t8_row3.tif\n",
      " 93 \t half-x_s2_t8_row4.tif\n",
      " 94 \t half-x_s2_t8_row5.tif\n",
      " 95 \t half-x_s2_t8_row6.tif\n"
     ]
    }
   ],
   "source": [
    "directory = \"Z\"\n",
    "big_exp = \"7-8-23 the last Big One\"\n",
    "exp = \"all half-x tiff files\"  # - normalized\n",
    "data_dir_s1 = directory+\":\\\\Gregor L\\\\Kai colloids revisions\\\\\"+big_exp+\"\\\\\"+exp+\"\\\\s1\\\\\"\n",
    "data_dir_s2 = directory+\":\\\\Gregor L\\\\Kai colloids revisions\\\\\"+big_exp+\"\\\\\"+exp+\"\\\\s2\\\\\"\n",
    "#data_dir_quarterX_s1 = directory+\":\\\\Gregor L\\\\Kai colloids revisions\\\\\"+exp+\"\\\\all quarter-x tiff files\\\\s1\\\\\"\n",
    "#data_dir_quarterX_s2 = directory+\":\\\\Gregor L\\\\Kai colloids revisions\\\\\"+exp+\"\\\\all quarter-x tiff files\\\\s2\\\\\"\n",
    "\n",
    "data_saveto = directory+\":\\\\Gregor L\\\\Kai colloids revisions\\\\SIA\\\\revisions data\\\\\" #bottom_row_t01\\\\\n",
    "\n",
    "s1_files = glob.glob(data_dir_s1+\"*_t*\")  \n",
    "s2_files = glob.glob(data_dir_s2+\"*_t*\")  \n",
    "#files_quarterX_s1 = glob.glob(data_dir_quarterX_s1+\"*_t*\")  \n",
    "#files_quarterX_s2 = glob.glob(data_dir_quarterX_s2+\"*_t*\")  \n",
    "\n",
    "#print(\"found %i files\" % len(files_95_s1))\n",
    "#print (' \\thalf-x s1 \\t\\thalf-x s2 \\t\\tquarter-x s1 \\t\\t   quarter-x s2')\n",
    "\n",
    "all_files = []\n",
    "for i in range(len(s2_files)):\n",
    "    all_files.append(s1_files[i])\n",
    "    \n",
    "for i in range(len(s2_files)):\n",
    "    all_files.append(s2_files[i])\n",
    "\n",
    "\n",
    "for i,f in enumerate(all_files): print (' %i \\t %s' % (i, f.split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify pixel size, each condition (frame_names), and the time points of data collection (time_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file dimensions: (5, 1440, 1920)\n",
      "total number of time points: 8\n",
      "(for image previews) number of rows = 4\n"
     ]
    }
   ],
   "source": [
    "frame_names = [\"WT KaiC\", \"EA KaiC\", \"AE KaiC\"]\n",
    "### array containing the name for each frame in a tiff file to be run \n",
    "### e.g. frame 1 is an image of the \"50% bKaiB\" condition, frame 2 is an image of the \"35% bKaiB\" condition, etc.\n",
    "\n",
    "total_rows = 3\n",
    "\n",
    "time_array = [1, 4, 10, 14, 18, 21, 25, 28]\n",
    "#s1 [0.7, 3.7, 6.7, 10.0, 12.8, 17.7, 21.7, 24.9, 28.2]\n",
    "#s2 [1.0, 3.8, 6.8, 10.2, 13.1, 18.0, 21.9, 25.3, 28.7]\n",
    "### array containing the time points corresponding to consecutive tiff files\n",
    "### e.g. tiff files \"bottom_row_t1\", \"middle_row_t1\", and \"top_row_t1\" all correspond to t = 0.5 hrs, time_array[0]\n",
    "\n",
    "#pixel_size = 0.364 # 4*0.091 = 0.364\n",
    "pixels_per_bead = 11\n",
    "### pixel size (microns per pixel) of frames/ images in the tiff files --- 40x olympus objective => 0.091 um/px\n",
    "### IF 2x2 BINNING: multiply the original pixel size by 2^2 = 4, e.g. 4*(0.091 um/px) = 0.364 um/px\n",
    "\n",
    "eg_im= io.imread(all_files[0])  #tiff_file.imread(files[0])\n",
    "\n",
    "\n",
    "print(\"file dimensions: \"+ str(eg_im.shape))\n",
    "\n",
    "num_times = 8 #int((len(s1_files))/total_rows)\n",
    "print(\"total number of time points: \"+ str(num_times))\n",
    "if num_times % 2 == 0:\n",
    "    num_rows = int(num_times/2)\n",
    "else:\n",
    "    num_rows = int((num_times+1)/2)\n",
    "print(\"(for image previews) number of rows = \" + str(num_rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose size, font, and quality level (dpi_num) for the plots to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = 7,6\n",
    "###  size of output figures\n",
    "font_size = 20\n",
    "### font size\n",
    "dpi_num = 600\n",
    "### image quality level (recommendation: 600)\n",
    "svg_saveto = directory+\":\\\\Gregor L\\\\Kai colloids revisions\\\\SIA\\\\svg files\\\\\"\n",
    "data_saveto = directory+\":\\\\Gregor L\\\\Kai colloids revisions\\\\SIA\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# For better results, we filter & 'skeletonize' the images before analysis \n",
    "### Do we need to filter out background noise from the images? If so, we can try out different filter sizes to see which works best. The following block previews the images intended for SIA analysis, showing the filtered and skeletonized images\n",
    "'skeletonize' means we find a specific threshold (based on median intensity), so all pixel values above that threshold = 1, and all pixel values below that threshold = 0. This gives structures clean borders for improved correlation analysis, g(r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 960)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_avg_gr = np.zeros((4, num_times, 960))\n",
    "all_gr_stdE = np.zeros((4, num_times, 960))\n",
    "\n",
    "all_avg_fits = np.zeros((4, num_times, 1000))\n",
    "all_fits_stdE = np.zeros((4, num_times, 1000))\n",
    "\n",
    "all_avg_A = np.zeros((4, num_times))\n",
    "all_A_stdE =np.zeros((4, num_times))\n",
    "\n",
    "all_avg_cl = np.zeros((4, num_times))\n",
    "all_cl_stdE =np.zeros((4, num_times))\n",
    "\n",
    "all_avg_gr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def select_cmap(frame_key):\n",
    "    if frame_key == 0:\n",
    "        print(\"WT+kaiA\")\n",
    "        #matplotlib.cm.get_cmap('Reds')\n",
    "        return 'o', 'm', matplotlib.colormaps['RdPu'], \"WT KaiC\" \n",
    "    elif frame_key == 1:\n",
    "        print(\"EA\")\n",
    "        return '^', 'c', matplotlib.colormaps['Blues'], \"pS KaiC\"  \n",
    "    elif frame_key == 2:\n",
    "        print(\"AE\")\n",
    "        return 's', 'k', matplotlib.colormaps['gist_yarg'], \"pT KaiC\" \n",
    "    \n",
    "def select_data_arrays(t_num):\n",
    "    if t_num == 1:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t1_gr_curve, t1_gr_fits, t1_A_vals, t1_cl_vals\n",
    "    if t_num == 2:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t2_gr_curve, t2_gr_fits, t2_A_vals, t2_cl_vals\n",
    "    if t_num == 3:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t3_gr_curve, t3_gr_fits, t3_A_vals, t3_cl_vals\n",
    "    if t_num == 4:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t4_gr_curve, t4_gr_fits, t4_A_vals, t4_cl_vals\n",
    "    if t_num == 5:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t5_gr_curve, t5_gr_fits, t5_A_vals, t5_cl_vals\n",
    "    if t_num == 6:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t6_gr_curve, t6_gr_fits, t6_A_vals, t6_cl_vals\n",
    "    if t_num == 7:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t7_gr_curve, t7_gr_fits, t7_A_vals, t7_cl_vals\n",
    "    if t_num == 8:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t8_gr_curve, t8_gr_fits, t8_A_vals, t8_cl_vals\n",
    "    if t_num == 9:\n",
    "        print(\"selected arrays for t_num= \"+str(t_num)+\", \"+str(time_array[t_num -1])+\" hrs\")\n",
    "        return t9_gr_curve, t9_gr_fits, t9_A_vals, t9_cl_vals\n",
    "\n",
    "    \n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.linewidth'] = 2.2 #set the value globally\n",
    "mpl.rcParams['mathtext.default'] = 'regular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_results(frame_key):\n",
    "    if frame_key == 0:\n",
    "        print(\"WT\")\n",
    "        #matplotlib.cm.get_cmap('Reds')\n",
    "        return WTkA_all_t_A_vals, WTkA_all_t_cl_vals, \"WT KaiC\" \n",
    "    elif frame_key == 1:\n",
    "        print(\"EA\")\n",
    "        return EA_all_t_A_vals, EA_all_t_cl_vals, \"pS KaiC\"\n",
    "    elif frame_key == 2:\n",
    "        print(\"AE\")\n",
    "        return AE_all_t_A_vals, AE_all_t_cl_vals, \"pT KaiC\" \n",
    "    \n",
    "ims_per_t = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_gr_curve = np.zeros((ims_per_t,960))\n",
    "t2_gr_curve = np.zeros((ims_per_t,960))\n",
    "t3_gr_curve = np.zeros((ims_per_t,960))\n",
    "t4_gr_curve = np.zeros((ims_per_t,960))\n",
    "t5_gr_curve = np.zeros((ims_per_t,960))\n",
    "t6_gr_curve = np.zeros((ims_per_t,960))\n",
    "t7_gr_curve = np.zeros((ims_per_t,960))\n",
    "t8_gr_curve = np.zeros((ims_per_t,960))\n",
    "t9_gr_curve = np.zeros((ims_per_t,960))\n",
    "\n",
    "t1_gr_fits = np.zeros((ims_per_t,1000))\n",
    "t2_gr_fits = np.zeros((ims_per_t,1000))\n",
    "t3_gr_fits = np.zeros((ims_per_t,1000))\n",
    "t4_gr_fits = np.zeros((ims_per_t,1000))\n",
    "t5_gr_fits = np.zeros((ims_per_t,1000))\n",
    "t6_gr_fits = np.zeros((ims_per_t,1000))\n",
    "t7_gr_fits = np.zeros((ims_per_t,1000))\n",
    "t8_gr_fits = np.zeros((ims_per_t,1000))\n",
    "t9_gr_fits = np.zeros((ims_per_t,1000))\n",
    "\n",
    "t1_A_vals = np.zeros((ims_per_t,1))\n",
    "t2_A_vals = np.zeros((ims_per_t,1))\n",
    "t3_A_vals = np.zeros((ims_per_t,1))\n",
    "t4_A_vals = np.zeros((ims_per_t,1))\n",
    "t5_A_vals = np.zeros((ims_per_t,1))\n",
    "t6_A_vals = np.zeros((ims_per_t,1))\n",
    "t7_A_vals = np.zeros((ims_per_t,1))\n",
    "t8_A_vals = np.zeros((ims_per_t,1))\n",
    "t9_A_vals = np.zeros((ims_per_t,1))\n",
    "\n",
    "t1_cl_vals = np.zeros((ims_per_t,1))\n",
    "t2_cl_vals = np.zeros((ims_per_t,1))\n",
    "t3_cl_vals = np.zeros((ims_per_t,1))\n",
    "t4_cl_vals = np.zeros((ims_per_t,1))\n",
    "t5_cl_vals = np.zeros((ims_per_t,1))\n",
    "t6_cl_vals = np.zeros((ims_per_t,1))\n",
    "t7_cl_vals = np.zeros((ims_per_t,1))\n",
    "t8_cl_vals = np.zeros((ims_per_t,1))\n",
    "t9_cl_vals = np.zeros((ims_per_t,1))\n",
    "\n",
    "\n",
    "row_to_write = [''] * 11 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk = 0\n",
    "condition = frame_names[fk]\n",
    "\n",
    "ims_each_time = 12\n",
    "\n",
    "block_size = 1051\n",
    "offset_val = -20\n",
    "\n",
    "fit_start = 0\n",
    "fit_lim = -1 \n",
    "\n",
    "all_xvalues = np.arange(960)/ pixels_per_bead\n",
    "x_fit_values = np.linspace(all_xvalues[fit_start], all_xvalues[fit_lim], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'half-x_s2_t8_row6.tif'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(all_files[j].split('\\\\')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can run some SIA! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition: EA KaiC\t time: 1 hrs\n",
      "selected arrays for t_num= 1, 1 hrs\n",
      "half-x_s1_t1_row1.tif\n",
      "half-x_s1_t1_row2.tif\n",
      "half-x_s1_t1_row3.tif\n",
      "half-x_s1_t1_row4.tif\n",
      "half-x_s1_t1_row5.tif\n",
      "half-x_s1_t1_row6.tif\n",
      "half-x_s2_t1_row1.tif\n",
      "half-x_s2_t1_row2.tif\n",
      "half-x_s2_t1_row3.tif\n",
      "half-x_s2_t1_row4.tif\n",
      "half-x_s2_t1_row5.tif\n",
      "half-x_s2_t1_row6.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\957607373.py:43: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  all_avg_A[fk,i] = A_vals.mean(axis=0)\n",
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\957607373.py:44: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  all_A_stdE[fk,i] = (A_vals.std(axis=0))/np.sqrt(ims_each_time)\n",
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\957607373.py:46: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  all_avg_cl[fk,i] = cl_vals.mean(axis=0)\n",
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\957607373.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  all_cl_stdE[fk,i] = (cl_vals.std(axis=0))/np.sqrt(ims_each_time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition: EA KaiC\t time: 4 hrs\n",
      "selected arrays for t_num= 2, 4 hrs\n",
      "half-x_s1_t2_row1.tif\n",
      "half-x_s1_t2_row2.tif\n",
      "half-x_s1_t2_row3.tif\n",
      "half-x_s1_t2_row4.tif\n",
      "half-x_s1_t2_row5.tif\n",
      "half-x_s1_t2_row6.tif\n",
      "half-x_s2_t2_row1.tif\n",
      "half-x_s2_t2_row2.tif\n",
      "half-x_s2_t2_row3.tif\n",
      "half-x_s2_t2_row4.tif\n",
      "half-x_s2_t2_row5.tif\n",
      "half-x_s2_t2_row6.tif\n",
      "condition: EA KaiC\t time: 10 hrs\n",
      "selected arrays for t_num= 3, 10 hrs\n",
      "half-x_s1_t3_row1.tif\n",
      "half-x_s1_t3_row2.tif\n",
      "half-x_s1_t3_row3.tif\n",
      "half-x_s1_t3_row4.tif\n",
      "half-x_s1_t3_row5.tif\n",
      "half-x_s1_t3_row6.tif\n",
      "half-x_s2_t3_row1.tif\n",
      "half-x_s2_t3_row2.tif\n",
      "half-x_s2_t3_row3.tif\n",
      "half-x_s2_t3_row4.tif\n",
      "half-x_s2_t3_row5.tif\n",
      "half-x_s2_t3_row6.tif\n",
      "condition: EA KaiC\t time: 14 hrs\n",
      "selected arrays for t_num= 4, 14 hrs\n",
      "half-x_s1_t4_row1.tif\n",
      "half-x_s1_t4_row2.tif\n",
      "half-x_s1_t4_row3.tif\n",
      "half-x_s1_t4_row4.tif\n",
      "half-x_s1_t4_row5.tif\n",
      "half-x_s1_t4_row6.tif\n",
      "half-x_s2_t4_row1.tif\n",
      "half-x_s2_t4_row2.tif\n",
      "half-x_s2_t4_row3.tif\n",
      "half-x_s2_t4_row4.tif\n",
      "half-x_s2_t4_row5.tif\n",
      "half-x_s2_t4_row6.tif\n",
      "condition: EA KaiC\t time: 18 hrs\n",
      "selected arrays for t_num= 5, 18 hrs\n",
      "half-x_s1_t5_row1.tif\n",
      "half-x_s1_t5_row2.tif\n",
      "half-x_s1_t5_row3.tif\n",
      "half-x_s1_t5_row4.tif\n",
      "half-x_s1_t5_row5.tif\n",
      "half-x_s1_t5_row6.tif\n",
      "half-x_s2_t5_row1.tif\n",
      "half-x_s2_t5_row2.tif\n",
      "half-x_s2_t5_row3.tif\n",
      "half-x_s2_t5_row4.tif\n",
      "half-x_s2_t5_row5.tif\n",
      "half-x_s2_t5_row6.tif\n",
      "condition: EA KaiC\t time: 21 hrs\n",
      "selected arrays for t_num= 6, 21 hrs\n",
      "half-x_s1_t6_row1.tif\n",
      "half-x_s1_t6_row2.tif\n",
      "half-x_s1_t6_row3.tif\n",
      "half-x_s1_t6_row4.tif\n",
      "half-x_s1_t6_row5.tif\n",
      "half-x_s1_t6_row6.tif\n",
      "half-x_s2_t6_row1.tif\n",
      "half-x_s2_t6_row2.tif\n",
      "half-x_s2_t6_row3.tif\n",
      "half-x_s2_t6_row4.tif\n",
      "half-x_s2_t6_row5.tif\n",
      "half-x_s2_t6_row6.tif\n",
      "condition: EA KaiC\t time: 25 hrs\n",
      "selected arrays for t_num= 7, 25 hrs\n",
      "half-x_s1_t7_row1.tif\n",
      "half-x_s1_t7_row2.tif\n",
      "half-x_s1_t7_row3.tif\n",
      "half-x_s1_t7_row4.tif\n",
      "half-x_s1_t7_row5.tif\n",
      "half-x_s1_t7_row6.tif\n",
      "half-x_s2_t7_row1.tif\n",
      "half-x_s2_t7_row2.tif\n",
      "half-x_s2_t7_row3.tif\n",
      "half-x_s2_t7_row4.tif\n",
      "half-x_s2_t7_row5.tif\n",
      "half-x_s2_t7_row6.tif\n",
      "condition: EA KaiC\t time: 28 hrs\n",
      "selected arrays for t_num= 8, 28 hrs\n",
      "half-x_s1_t8_row1.tif\n",
      "half-x_s1_t8_row2.tif\n",
      "half-x_s1_t8_row3.tif\n",
      "half-x_s1_t8_row4.tif\n",
      "half-x_s1_t8_row5.tif\n",
      "half-x_s1_t8_row6.tif\n",
      "half-x_s2_t8_row1.tif\n",
      "half-x_s2_t8_row2.tif\n",
      "half-x_s2_t8_row3.tif\n",
      "half-x_s2_t8_row4.tif\n",
      "half-x_s2_t8_row5.tif\n",
      "half-x_s2_t8_row6.tif\n"
     ]
    }
   ],
   "source": [
    "fk = 1\n",
    "condition = frame_names[fk]\n",
    "\n",
    "ims_each_time = 12\n",
    "\n",
    "block_size = 1051\n",
    "offset_val = -20\n",
    "\n",
    "fit_start = 0\n",
    "fit_lim = -1 \n",
    "\n",
    "all_xvalues = np.arange(960)/ pixels_per_bead\n",
    "x_fit_values = np.linspace(all_xvalues[fit_start], all_xvalues[fit_lim], 1000)\n",
    "for i in range(num_times):\n",
    "    time = str(time_array[i])\n",
    "    print(\"condition: \"+condition + \"\\t time: \"+time+\" hrs\")\n",
    "    t_num = 1 + i\n",
    "    gr_curves, gr_fits, A_vals, cl_vals = select_data_arrays(t_num)\n",
    "    one_time_all = []\n",
    "    for j in range(len(all_files)): \n",
    "        t = str(all_files[j].split('\\\\')[-1][10:-9])\n",
    "        if t == ('t0'+str(t_num)) or t == ('t'+str(t_num)):\n",
    "            print(all_files[j].split('\\\\')[-1])\n",
    "            one_time_all.append(all_files[j])\n",
    "            \n",
    "    for g in range(ims_each_time):\n",
    "        gr_curves[g] = SIA(tiff_file.imread(one_time_all[g],key=[fk]),block_size, offset_val)\n",
    "    \n",
    "    all_avg_gr[fk,i] = gr_curves.mean(axis=0)\n",
    "    all_gr_stdE[fk,i] = (gr_curves.std(axis=0))/np.sqrt(ims_each_time)\n",
    "    \n",
    "    for f in range(ims_each_time):\n",
    "        y_array = gr_curves[f]\n",
    "        popt, pcov = curve_fit(single_exponential, all_xvalues[fit_start:fit_lim], y_array[fit_start:fit_lim])\n",
    "        A, cl = tuple(popt)\n",
    "        gr_fits[f] = single_exponential(x_fit_values, *popt)\n",
    "        A_vals[f] = A\n",
    "        cl_vals[f] = cl\n",
    "        \n",
    "    all_avg_fits[fk,i] = gr_fits.mean(axis=0)\n",
    "    all_fits_stdE[fk,i] = (gr_fits.std(axis=0))/np.sqrt(ims_each_time)\n",
    "\n",
    "    all_avg_A[fk,i] = A_vals.mean(axis=0)\n",
    "    all_A_stdE[fk,i] = (A_vals.std(axis=0))/np.sqrt(ims_each_time)\n",
    "\n",
    "    all_avg_cl[fk,i] = cl_vals.mean(axis=0)\n",
    "    all_cl_stdE[fk,i] = (cl_vals.std(axis=0))/np.sqrt(ims_each_time)\n",
    "    \n",
    "'''if fk == 0:\n",
    "    WTkA_all_t_A_vals=[t1_A_vals, t2_A_vals, t3_A_vals, t4_A_vals,\n",
    "                       t5_A_vals, t6_A_vals, t7_A_vals, t8_A_vals, t9_A_vals]\n",
    "    WTkA_all_t_cl_vals=[t1_cl_vals, t2_cl_vals, t3_cl_vals, t4_cl_vals,\n",
    "                       t5_cl_vals, t6_cl_vals, t7_cl_vals, t8_cl_vals, t9_cl_vals]'''\n",
    "\n",
    "if fk == 1:\n",
    "    EA_all_t_A_vals=[t1_A_vals, t2_A_vals, t3_A_vals, t4_A_vals,\n",
    "                     t5_A_vals, t6_A_vals, t7_A_vals, t8_A_vals, t9_A_vals]\n",
    "    EA_all_t_cl_vals=[t1_cl_vals, t2_cl_vals, t3_cl_vals, t4_cl_vals,\n",
    "                      t5_cl_vals, t6_cl_vals, t7_cl_vals, t8_cl_vals, t9_cl_vals] \n",
    "if fk == 2:\n",
    "    AE_all_t_A_vals=[t1_A_vals, t2_A_vals, t3_A_vals, t4_A_vals,\n",
    "                     t5_A_vals, t6_A_vals, t7_A_vals, t8_A_vals, t9_A_vals]\n",
    "    AE_all_t_cl_vals=[t1_cl_vals, t2_cl_vals, t3_cl_vals, t4_cl_vals,\n",
    "                      t5_cl_vals, t6_cl_vals, t7_cl_vals, t8_cl_vals, t9_cl_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition: AE KaiC\t time: 1 hrs\n",
      "selected arrays for t_num= 1, 1 hrs\n",
      "half-x_s1_t1_row1.tif\n",
      "half-x_s1_t1_row2.tif\n",
      "half-x_s1_t1_row3.tif\n",
      "half-x_s1_t1_row4.tif\n",
      "half-x_s1_t1_row5.tif\n",
      "half-x_s1_t1_row6.tif\n",
      "half-x_s2_t1_row1.tif\n",
      "half-x_s2_t1_row2.tif\n",
      "half-x_s2_t1_row3.tif\n",
      "half-x_s2_t1_row4.tif\n",
      "half-x_s2_t1_row5.tif\n",
      "half-x_s2_t1_row6.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\3793139348.py:43: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  all_avg_A[fk,i] = A_vals.mean(axis=0)\n",
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\3793139348.py:44: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  all_A_stdE[fk,i] = (A_vals.std(axis=0))/np.sqrt(ims_each_time)\n",
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\3793139348.py:46: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  all_avg_cl[fk,i] = cl_vals.mean(axis=0)\n",
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\3793139348.py:47: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  all_cl_stdE[fk,i] = (cl_vals.std(axis=0))/np.sqrt(ims_each_time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition: AE KaiC\t time: 4 hrs\n",
      "selected arrays for t_num= 2, 4 hrs\n",
      "half-x_s1_t2_row1.tif\n",
      "half-x_s1_t2_row2.tif\n",
      "half-x_s1_t2_row3.tif\n",
      "half-x_s1_t2_row4.tif\n",
      "half-x_s1_t2_row5.tif\n",
      "half-x_s1_t2_row6.tif\n",
      "half-x_s2_t2_row1.tif\n",
      "half-x_s2_t2_row2.tif\n",
      "half-x_s2_t2_row3.tif\n",
      "half-x_s2_t2_row4.tif\n",
      "half-x_s2_t2_row5.tif\n",
      "half-x_s2_t2_row6.tif\n",
      "condition: AE KaiC\t time: 10 hrs\n",
      "selected arrays for t_num= 3, 10 hrs\n",
      "half-x_s1_t3_row1.tif\n",
      "half-x_s1_t3_row2.tif\n",
      "half-x_s1_t3_row3.tif\n",
      "half-x_s1_t3_row4.tif\n",
      "half-x_s1_t3_row5.tif\n",
      "half-x_s1_t3_row6.tif\n",
      "half-x_s2_t3_row1.tif\n",
      "half-x_s2_t3_row2.tif\n",
      "half-x_s2_t3_row3.tif\n",
      "half-x_s2_t3_row4.tif\n",
      "half-x_s2_t3_row5.tif\n",
      "half-x_s2_t3_row6.tif\n",
      "condition: AE KaiC\t time: 14 hrs\n",
      "selected arrays for t_num= 4, 14 hrs\n",
      "half-x_s1_t4_row1.tif\n",
      "half-x_s1_t4_row2.tif\n",
      "half-x_s1_t4_row3.tif\n",
      "half-x_s1_t4_row4.tif\n",
      "half-x_s1_t4_row5.tif\n",
      "half-x_s1_t4_row6.tif\n",
      "half-x_s2_t4_row1.tif\n",
      "half-x_s2_t4_row2.tif\n",
      "half-x_s2_t4_row3.tif\n",
      "half-x_s2_t4_row4.tif\n",
      "half-x_s2_t4_row5.tif\n",
      "half-x_s2_t4_row6.tif\n",
      "condition: AE KaiC\t time: 18 hrs\n",
      "selected arrays for t_num= 5, 18 hrs\n",
      "half-x_s1_t5_row1.tif\n",
      "half-x_s1_t5_row2.tif\n",
      "half-x_s1_t5_row3.tif\n",
      "half-x_s1_t5_row4.tif\n",
      "half-x_s1_t5_row5.tif\n",
      "half-x_s1_t5_row6.tif\n",
      "half-x_s2_t5_row1.tif\n",
      "half-x_s2_t5_row2.tif\n",
      "half-x_s2_t5_row3.tif\n",
      "half-x_s2_t5_row4.tif\n",
      "half-x_s2_t5_row5.tif\n",
      "half-x_s2_t5_row6.tif\n",
      "condition: AE KaiC\t time: 21 hrs\n",
      "selected arrays for t_num= 6, 21 hrs\n",
      "half-x_s1_t6_row1.tif\n",
      "half-x_s1_t6_row2.tif\n",
      "half-x_s1_t6_row3.tif\n",
      "half-x_s1_t6_row4.tif\n",
      "half-x_s1_t6_row5.tif\n",
      "half-x_s1_t6_row6.tif\n",
      "half-x_s2_t6_row1.tif\n",
      "half-x_s2_t6_row2.tif\n",
      "half-x_s2_t6_row3.tif\n",
      "half-x_s2_t6_row4.tif\n",
      "half-x_s2_t6_row5.tif\n",
      "half-x_s2_t6_row6.tif\n",
      "condition: AE KaiC\t time: 25 hrs\n",
      "selected arrays for t_num= 7, 25 hrs\n",
      "half-x_s1_t7_row1.tif\n",
      "half-x_s1_t7_row2.tif\n",
      "half-x_s1_t7_row3.tif\n",
      "half-x_s1_t7_row4.tif\n",
      "half-x_s1_t7_row5.tif\n",
      "half-x_s1_t7_row6.tif\n",
      "half-x_s2_t7_row1.tif\n",
      "half-x_s2_t7_row2.tif\n",
      "half-x_s2_t7_row3.tif\n",
      "half-x_s2_t7_row4.tif\n",
      "half-x_s2_t7_row5.tif\n",
      "half-x_s2_t7_row6.tif\n",
      "condition: AE KaiC\t time: 28 hrs\n",
      "selected arrays for t_num= 8, 28 hrs\n",
      "half-x_s1_t8_row1.tif\n",
      "half-x_s1_t8_row2.tif\n",
      "half-x_s1_t8_row3.tif\n",
      "half-x_s1_t8_row4.tif\n",
      "half-x_s1_t8_row5.tif\n",
      "half-x_s1_t8_row6.tif\n",
      "half-x_s2_t8_row1.tif\n",
      "half-x_s2_t8_row2.tif\n",
      "half-x_s2_t8_row3.tif\n",
      "half-x_s2_t8_row4.tif\n",
      "half-x_s2_t8_row5.tif\n",
      "half-x_s2_t8_row6.tif\n"
     ]
    }
   ],
   "source": [
    "fk = 2\n",
    "condition = frame_names[fk]\n",
    "\n",
    "ims_each_time = 12\n",
    "\n",
    "block_size = 1051\n",
    "offset_val = -20\n",
    "\n",
    "fit_start = 0\n",
    "fit_lim = -1 \n",
    "\n",
    "all_xvalues = np.arange(960)/ pixels_per_bead\n",
    "x_fit_values = np.linspace(all_xvalues[fit_start], all_xvalues[fit_lim], 1000)\n",
    "for i in range(num_times):\n",
    "    time = str(time_array[i])\n",
    "    print(\"condition: \"+condition + \"\\t time: \"+time+\" hrs\")\n",
    "    t_num = 1 + i\n",
    "    gr_curves, gr_fits, A_vals, cl_vals = select_data_arrays(t_num)\n",
    "    one_time_all = []\n",
    "    for j in range(len(all_files)): \n",
    "        t = str(all_files[j].split('\\\\')[-1][10:-9])\n",
    "        if t == ('t0'+str(t_num)) or t == ('t'+str(t_num)):\n",
    "            print(all_files[j].split('\\\\')[-1])\n",
    "            one_time_all.append(all_files[j])\n",
    "            \n",
    "    for g in range(ims_each_time):\n",
    "        gr_curves[g] = SIA(tiff_file.imread(one_time_all[g],key=[fk]),block_size, offset_val)\n",
    "    \n",
    "    all_avg_gr[fk,i] = gr_curves.mean(axis=0)\n",
    "    all_gr_stdE[fk,i] = (gr_curves.std(axis=0))/np.sqrt(ims_each_time)\n",
    "    \n",
    "    for f in range(ims_each_time):\n",
    "        y_array = gr_curves[f]\n",
    "        popt, pcov = curve_fit(single_exponential, all_xvalues[fit_start:fit_lim], y_array[fit_start:fit_lim])\n",
    "        A, cl = tuple(popt)\n",
    "        gr_fits[f] = single_exponential(x_fit_values, *popt)\n",
    "        A_vals[f] = A\n",
    "        cl_vals[f] = cl\n",
    "        \n",
    "    all_avg_fits[fk,i] = gr_fits.mean(axis=0)\n",
    "    all_fits_stdE[fk,i] = (gr_fits.std(axis=0))/np.sqrt(ims_each_time)\n",
    "\n",
    "    all_avg_A[fk,i] = A_vals.mean(axis=0)\n",
    "    all_A_stdE[fk,i] = (A_vals.std(axis=0))/np.sqrt(ims_each_time)\n",
    "\n",
    "    all_avg_cl[fk,i] = cl_vals.mean(axis=0)\n",
    "    all_cl_stdE[fk,i] = (cl_vals.std(axis=0))/np.sqrt(ims_each_time)\n",
    "    \n",
    "'''if fk == 0:\n",
    "    WTkA_all_t_A_vals=[t1_A_vals, t2_A_vals, t3_A_vals, t4_A_vals,\n",
    "                       t5_A_vals, t6_A_vals, t7_A_vals, t8_A_vals, t9_A_vals]\n",
    "    WTkA_all_t_cl_vals=[t1_cl_vals, t2_cl_vals, t3_cl_vals, t4_cl_vals,\n",
    "                       t5_cl_vals, t6_cl_vals, t7_cl_vals, t8_cl_vals, t9_cl_vals]'''\n",
    "\n",
    "'''if fk == 1:\n",
    "    EA_all_t_A_vals=[t1_A_vals, t2_A_vals, t3_A_vals, t4_A_vals,\n",
    "                     t5_A_vals, t6_A_vals, t7_A_vals, t8_A_vals, t9_A_vals]\n",
    "    EA_all_t_cl_vals=[t1_cl_vals, t2_cl_vals, t3_cl_vals, t4_cl_vals,\n",
    "                      t5_cl_vals, t6_cl_vals, t7_cl_vals, t8_cl_vals, t9_cl_vals] '''\n",
    "if fk == 2:\n",
    "    AE_all_t_A_vals=[t1_A_vals, t2_A_vals, t3_A_vals, t4_A_vals,\n",
    "                     t5_A_vals, t6_A_vals, t7_A_vals, t8_A_vals, t9_A_vals]\n",
    "    AE_all_t_cl_vals=[t1_cl_vals, t2_cl_vals, t3_cl_vals, t4_cl_vals,\n",
    "                      t5_cl_vals, t6_cl_vals, t7_cl_vals, t8_cl_vals, t9_cl_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t WT KaiC \t EA (pS) KaiC \t AE (pT) KaiC\n",
      "t= 1 hrs --> \t 0.77 \t\t 0.77 \t\t 0.77\n",
      "t= 4 hrs --> \t 0.74 \t\t 0.74 \t\t 0.74\n",
      "t= 10 hrs --> \t 0.78 \t\t 0.78 \t\t 0.78\n",
      "t= 14 hrs --> \t 0.76 \t\t 0.76 \t\t 0.76\n",
      "t= 18 hrs --> \t 0.75 \t\t 0.75 \t\t 0.75\n",
      "t= 21 hrs --> \t 0.76 \t\t 0.76 \t\t 0.76\n",
      "t= 25 hrs --> \t 0.80 \t\t 0.80 \t\t 0.80\n",
      "t= 28 hrs --> \t 0.76 \t\t 0.76 \t\t 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gleech\\AppData\\Local\\Temp\\ipykernel_33940\\880683971.py:2: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  for i in range(8): print ('t= %i hrs --> \\t %1.2f \\t\\t %1.2f \\t\\t %1.2f' % (time_array[i], WTkA_all_t_cl_vals[i][0],\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\t WT KaiC \\t EA (pS) KaiC \\t AE (pT) KaiC\")\n",
    "for i in range(8): print ('t= %i hrs --> \\t %1.2f \\t\\t %1.2f \\t\\t %1.2f' % (time_array[i], WTkA_all_t_cl_vals[i][0], \n",
    "                                                                             EA_all_t_cl_vals[i][0] , AE_all_t_cl_vals[i][0]))\n",
    "                                                \n",
    "\n",
    "#print(WTkA_all_t_cl_vals[0])\n",
    "#print(EA_all_t_cl_vals[0])\n",
    "#print(AE_all_t_cl_vals[0])\n",
    "from statistics import median\n",
    "from statistics import mode\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_median_cl = np.zeros((4, num_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_results(frame_key):\n",
    "    if frame_key == 0:\n",
    "        print(\"WT+kaiA\")\n",
    "        #matplotlib.cm.get_cmap('Reds')\n",
    "        return WTkA_all_t_A_vals, WTkA_all_t_cl_vals, \"Wild Type KaiC\" \n",
    "    elif frame_key == 1:\n",
    "        print(\"WT w/o kaiA\")\n",
    "        return matplotlib.cm.get_cmap('Blues'), WTnokA_all_t_clusters, \"WT KaiC (no KaiA)\"\n",
    "    elif frame_key == 2:\n",
    "        print(\"EA\")\n",
    "        return EA_all_t_A_vals, EA_all_t_cl_vals, \"pS KaiC\"  \n",
    "    elif frame_key == 3:\n",
    "        print(\"AE\")\n",
    "        return AE_all_t_A_vals, AE_all_t_cl_vals, \"pT KaiC\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk = 2\n",
    "all_t_A_vals, all_t_cl_vals, data_label = select_results(fk)\n",
    "for t in range(9):\n",
    "    all_median_cl[fk][t] = median((all_t_cl_vals[t] *1))\n",
    "print(\"median correlation lengths:\")\n",
    "print(all_median_cl[fk]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fk = 3\n",
    "all_t_A_vals, all_t_cl_vals, data_label = select_results(fk)\n",
    "for t in range(9):\n",
    "    all_median_cl[fk][t] = np.mean((all_t_cl_vals[t] *2))\n",
    "print(\"mean correlation lengths:\")\n",
    "print(\"    %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f\" %(all_median_cl[fk][0],all_median_cl[fk][1],\n",
    "                                                                        all_median_cl[fk][2],all_median_cl[fk][3],\n",
    "                                                                        all_median_cl[fk][4],all_median_cl[fk][5],\n",
    "                                                                        all_median_cl[fk][6],all_median_cl[fk][7],\n",
    "                                                                        all_median_cl[fk][8]))\n",
    "for t in range(9):\n",
    "    all_median_cl[fk][t] = median((all_t_cl_vals[t] *2))\n",
    "print(\"median correlation lengths:\")\n",
    "print(\"    %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f\" %(all_median_cl[fk][0],all_median_cl[fk][1],\n",
    "                                                                        all_median_cl[fk][2],all_median_cl[fk][3],\n",
    "                                                                        all_median_cl[fk][4],all_median_cl[fk][5],\n",
    "                                                                        all_median_cl[fk][6],all_median_cl[fk][7],\n",
    "                                                                        all_median_cl[fk][8]))\n",
    "print(\" \")\n",
    "\n",
    "fk = 2\n",
    "all_t_A_vals, all_t_cl_vals, data_label = select_results(fk)\n",
    "for t in range(9):\n",
    "    all_median_cl[fk][t] = np.mean((all_t_cl_vals[t] *2))\n",
    "print(\"mean correlation lengths:\")\n",
    "print(\"    %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f\" %(all_median_cl[fk][0],all_median_cl[fk][1],\n",
    "                                                                        all_median_cl[fk][2],all_median_cl[fk][3],\n",
    "                                                                        all_median_cl[fk][4],all_median_cl[fk][5],\n",
    "                                                                        all_median_cl[fk][6],all_median_cl[fk][7],\n",
    "                                                                        all_median_cl[fk][8]))\n",
    "for t in range(9):\n",
    "    all_median_cl[fk][t] = median((all_t_cl_vals[t] *2))\n",
    "print(\"median correlation lengths:\")\n",
    "print(\"    %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f\" %(all_median_cl[fk][0],all_median_cl[fk][1],\n",
    "                                                                        all_median_cl[fk][2],all_median_cl[fk][3],\n",
    "                                                                        all_median_cl[fk][4],all_median_cl[fk][5],\n",
    "                                                                        all_median_cl[fk][6],all_median_cl[fk][7],\n",
    "                                                                        all_median_cl[fk][8]))\n",
    "print(\" \")\n",
    "\n",
    "fk = 0\n",
    "all_t_A_vals, all_t_cl_vals, data_label = select_results(fk)\n",
    "for t in range(9):\n",
    "    all_median_cl[fk][t] = np.mean((all_t_cl_vals[t] *2))\n",
    "print(\"mean correlation lengths:\")\n",
    "print(\"    %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f\" %(all_median_cl[fk][0],all_median_cl[fk][1],\n",
    "                                                                        all_median_cl[fk][2],all_median_cl[fk][3],\n",
    "                                                                        all_median_cl[fk][4],all_median_cl[fk][5],\n",
    "                                                                        all_median_cl[fk][6],all_median_cl[fk][7],\n",
    "                                                                        all_median_cl[fk][8]))\n",
    "for t in range(9):\n",
    "    all_median_cl[fk][t] = median((all_t_cl_vals[t] *2))\n",
    "print(\"median correlation lengths:\")\n",
    "print(\"    %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f, %1.2f\" %(all_median_cl[fk][0],all_median_cl[fk][1],\n",
    "                                                                        all_median_cl[fk][2],all_median_cl[fk][3],\n",
    "                                                                        all_median_cl[fk][4],all_median_cl[fk][5],\n",
    "                                                                        all_median_cl[fk][6],all_median_cl[fk][7],\n",
    "                                                                        all_median_cl[fk][8]))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_avg_cl[2]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "results_dict[\"WTkA\"] = {} #creates sub dictionary (within results_dict) for each frame analyzed \n",
    "results_dict[\"WTkA\"][\"all_A_vals\"] = WTkA_all_t_A_vals\n",
    "results_dict[\"WTkA\"][\"all_cl_vals\"] = WTkA_all_t_cl_vals\n",
    "\n",
    "results_dict[\"EA\"] = {} #creates sub dictionary (within results_dict) for each frame analyzed \n",
    "results_dict[\"EA\"][\"all_A_vals\"] = EA_all_t_A_vals\n",
    "results_dict[\"EA\"][\"all_cl_vals\"] = EA_all_t_cl_vals\n",
    "\n",
    "results_dict[\"AE\"] = {} #creates sub dictionary (within results_dict) for each frame analyzed \n",
    "results_dict[\"AE\"][\"all_A_vals\"] = AE_all_t_A_vals\n",
    "results_dict[\"AE\"][\"all_cl_vals\"] = AE_all_t_cl_vals\n",
    "\n",
    "results_dict[\"avg_gr\"] = all_avg_gr\n",
    "results_dict[\"gr_stdE\"] = all_gr_stdE\n",
    "\n",
    "results_dict[\"avg_fits\"] = all_avg_fits\n",
    "results_dict[\"fits_stdE\"] = all_fits_stdE\n",
    "\n",
    "results_dict[\"avg_A\"] = all_avg_A\n",
    "results_dict[\"A_stdE\"] = all_A_stdE\n",
    "\n",
    "results_dict[\"median_cl\"] = all_median_cl\n",
    "results_dict[\"avg_cl\"] = all_avg_cl\n",
    "results_dict[\"cl_stdE\"] = all_cl_stdE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''file_title = \"all_SIA_dict\"\n",
    "file_to_write = open(data_saveto+file_title+\".p\", \"wb\")\n",
    "print(file_to_write)\n",
    "pickle.dump(results_dict, file_to_write)'''\n",
    "all_true_times = np.array([[0.7, 3.7, 6.7, 10.0, 12.8, 17.7, 21.7, 24.9, 28.2],\n",
    "                           [1.0, 3.8, 6.8, 10.2, 13.1, 18.0, 21.9, 25.3, 28.7],\n",
    "                           [1.1, 4.0, 7.4, 10.3, 14.7, 17.7, 20.3, 23.8, 27.0],\n",
    "                           [1.2, 4.4, 7.8, 10.8, 15.2, 18.3, 20.8, 24.3, 28.0]])\n",
    "#all_true_times?\n",
    "all_true_times.mean(axis=0)\n",
    "time_stdE = (all_true_times.std(axis=0))/np.sqrt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_title = \"all_SIA_dict\"\n",
    "with open(\"1x WT bead 1-30-23.pkl\", 'wb') as f:\n",
    "    pickle.dump(results_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dict_reloaded = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_title = \"all_SIA_dict\"\n",
    "with open(file_title+\".pkl\", 'rb') as f:\n",
    "    results_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WTkA_all_t_A_vals = results_dict[\"WTkA\"][\"all_A_vals\"]  \n",
    "WTkA_all_t_cl_vals = results_dict[\"WTkA\"][\"all_cl_vals\"]  \n",
    "\n",
    "EA_all_t_A_vals = results_dict[\"EA\"][\"all_A_vals\"]  \n",
    "EA_all_t_cl_vals = results_dict[\"EA\"][\"all_cl_vals\"]  \n",
    "\n",
    "AE_all_t_A_vals = results_dict[\"AE\"][\"all_A_vals\"]  \n",
    "AE_all_t_cl_vals = results_dict[\"AE\"][\"all_cl_vals\"]  \n",
    "\n",
    "all_avg_gr = results_dict[\"avg_gr\"]  \n",
    "all_gr_stdE = results_dict[\"gr_stdE\"]  \n",
    "\n",
    "all_avg_fits = results_dict[\"avg_fits\"]  \n",
    "all_fits_stdE = results_dict[\"fits_stdE\"]  \n",
    "\n",
    "all_avg_A = results_dict[\"avg_A\"]  \n",
    "all_A_stdE = results_dict[\"A_stdE\"]  \n",
    "\n",
    "all_median_cl = results_dict[\"median_cl\"] \n",
    "all_avg_cl = results_dict[\"avg_cl\"]  \n",
    "all_cl_stdE = results_dict[\"cl_stdE\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "font_size = 20\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "ax.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax.tick_params(axis='both', direction='in', which='minor', length=4, width=2, labelsize=font_size-4)\n",
    "\n",
    "marker = 'o'\n",
    "markerSize = 4.5\n",
    "marker2 = '--'\n",
    "linew = 1.0\n",
    "elinew = 1.1\n",
    "cap_size = 6.5\n",
    "\n",
    "lines1 = []                                \n",
    "lines2 = []\n",
    "time_arr = []\n",
    "\n",
    "fk = 3\n",
    "i=0\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "time = data_label+\", \"+str(time_array[i])+\" hrs\"\n",
    "time_arr.append(time)\n",
    "\n",
    "cmap = (matplotlib.cm.get_cmap('spring'))(0.99)\n",
    "ax.plot(x_fit_values, all_avg_fits[fk,i], marker2, linewidth=linew, c=cmap, alpha=(0.01+(i*0.05)))\n",
    "lines2 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=markerSize, c=cmap, alpha=(0.01+(i*0.05)), label = time)\n",
    "ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "            c=cmap, alpha=(0.01+(i*0.05))) \n",
    "ax.plot(x_fit_values, all_avg_fits[fk,i], marker2, linewidth=linew, c=cmap2(0.995-(i*0.12)), alpha= (0.995-(i*0.09)))\n",
    "lines1 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=markerSize, c=cmap2(0.995-(i*0.12)), alpha= (0.995-(i*0.09)))\n",
    "ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "            c=cmap2(0.995-(i*0.12)), alpha= (0.995-(i*0.09)))\n",
    "\n",
    "fk = 2\n",
    "i=0\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "time = data_label+\", \"+str(time_array[i])+\" hrs\"\n",
    "time_arr.append(time)\n",
    "lines2 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=markerSize, c=cmap, alpha=(0.02+(i*0.03)), label = time)\n",
    "ax.plot(x_fit_values, all_avg_fits[fk,i], marker2, linewidth=linew, c='b', alpha=0.995)\n",
    "lines1 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=markerSize, c='b', alpha=0.995)\n",
    "ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "            c='b', alpha=0.995) \n",
    "\n",
    "fk = 2\n",
    "i=6\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "time = data_label+\", \"+str(time_array[i])+\" hrs\"\n",
    "time_arr.append(time)\n",
    "ax.plot(x_fit_values, all_avg_fits[fk,i], marker2, linewidth=linew, c=cmap2(0.995-(i*0.122)), alpha=0.995)\n",
    "lines1 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=markerSize, c=cmap2(0.995-(i*0.122)), alpha=0.995)\n",
    "ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "            c=cmap2(0.995-(i*0.122)), alpha=0.995)\n",
    "\n",
    "ax.plot(x_fit_values, all_avg_fits[fk,i], marker2, linewidth=linew, c=cmap, alpha=(0.4+(i*0.03)))\n",
    "lines2 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=markerSize, c=cmap, alpha=(0.4+(i*0.03)), label = time)\n",
    "ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "            c=cmap, alpha=(0.4+(i*0.03)))  \n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim(0.09, 1.1)\n",
    "#ax.set_ylim(-0.03, 1.0)\n",
    "\n",
    "#ax.set_xscale(\"log\")\n",
    "#ax.set_xlim(0.085, 5.2) \n",
    "#ax.set_xlim(0.085, 15)\n",
    "ax.set_xlim(0.0, 4.9)\n",
    "#ax.set_xlim(0, 4.8)\n",
    "\n",
    "    \n",
    "title =  \"pT1, pS1, pS20\" #+ \" (normalized CDF)\"   #\"Time = \" + str(time) + \" hrs,\n",
    "ax.set_title(title, fontsize= (font_size))\n",
    "plt.ylabel('g(r)', fontsize=font_size, labelpad = -2)\n",
    "plt.xlabel('Distance (bead diameters)', fontsize=font_size-1)\n",
    "\n",
    "leg_loc= 'upper right'  #'lower left' #\n",
    "\n",
    "leg1 = ax.legend(markerscale=2.5, fontsize=font_size-6, loc = leg_loc, framealpha= 0, frameon=False)\n",
    "from matplotlib.legend import Legend\n",
    "leg2 = Legend(ax, lines1, time_arr, markerscale=2.5, fontsize=font_size-6,\n",
    "             loc=leg_loc, framealpha= 0, frameon=False)\n",
    "ax.add_artist(leg2)\n",
    "plt.subplots_adjust(bottom=0.1, left=0.15, right=0.95, top=0.9)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(data_saveto+ \"logy Fig3 SIA avg + error + fits \"+title+\".png\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "fig.savefig(svg_saveto+ \"logy Fig3 SIA avg + error + fits\"+title+\".svg\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "#fig.savefig(data_saveto+ \"SIA avg + error \"+title+\".png\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "#fig.savefig(svg_saveto+ \"SIA avg + error \"+title+\".svg\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "\n",
    "#fig.savefig(data_saveto+ \"all times SIA avg + error + fits \"+title+\".png\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "#fig.savefig(svg_saveto+ \"all times SIA avg + error + fits\"+title+\".svg\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "#fig.savefig(data_saveto+ \"all times SIA avg + error \"+title+\".png\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "#fig.savefig(svg_saveto+ \"all times SIA avg + error \"+title+\".svg\", dpi=800, bbox_inches ='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "font_size = 20\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "ax.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax.tick_params(axis='both', direction='in', which='minor', length=4, width=2, labelsize=font_size-4)\n",
    "\n",
    "marker = 'o'\n",
    "mS = 4\n",
    "marker2 = '--'\n",
    "linew = 1.0\n",
    "alpha_num = 0.99\n",
    "\n",
    "fk = 2\n",
    "#### up to 28 hrs\n",
    "#WT=> 'RdPu' cmap2(0.995-(i*0.122)), alpha=0.995)    cmap, alpha=(0.02+(i*0.03))\n",
    "#EA=> 'Blues'  cmap2(0.995-(i*0.122)), alpha=0.995)    cmap, alpha=(0.02+(i*0.039))\n",
    "#AE=> cmap= 'spring'  cmap2= 'gist_yarg' cmap2(0.995-(i*0.12)), alpha= (0.995-(i*0.09))  cmap, alpha=(0.01+(i*0.05))\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "lines1 = []                                \n",
    "lines2 = []\n",
    "lines3 = []\n",
    "time_arr = []\n",
    "for i in range(0,9,2):\n",
    "    time = str(time_array[i])+\" hrs\"\n",
    "    time_arr.append(time)\n",
    "    \n",
    "    '''  #AE:\n",
    "    cmap = (matplotlib.cm.get_cmap('spring'))(0.99)\n",
    "    lines1 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap2(0.99-(i*0.12)), alpha=(0.979-((i-1)*0.02)))\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap2(0.99-(i*0.12)), alpha=(0.979-((i-1)*0.02)))\n",
    "    lines2 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap, alpha=(0.08+((i-1)*0.07)))\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap, alpha=(0.08+((i-1)*0.07)))\n",
    "    lines3 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap2(0.999-(i*0.12)), alpha=0)\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap2(0.999-(i*0.12)), alpha=0)  #    '''\n",
    "    '''  #WT:\n",
    "    lines1 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap, alpha=(0.99-(i*0.092)))\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap, alpha=(0.99-(i*0.092)))\n",
    "    lines2 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap2(0.999-(i*0.123)), alpha=(0.6-((i-1)*0.07)))\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap2(0.999-(i*0.123)), alpha=(0.6-((i-1)*0.07)))\n",
    "    lines3 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap2(0.999-(i*0.124)), alpha=(0.6-((i-2)*0.085)))\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap2(0.999-(i*0.124)), alpha=(0.6-((i-2)*0.085)))  #    '''\n",
    "\n",
    "      #EA:\n",
    "    lines1 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap, alpha=(0.99-(i*0.08)))\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap, alpha=(0.99-(i*0.08)))\n",
    "    lines2 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap2(0.999-(i*0.1)), alpha=(0.6-((i-2)*0.04)))\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap2(0.999-(i*0.1)), alpha=(0.6-((i-2)*0.04)))\n",
    "    lines3 += ax.plot(all_xvalues, all_avg_gr[fk,i], marker, ms=mS, c=cmap2(0.999-(i*0.124)), alpha=(0.7-((i-2)*0.045)))\n",
    "    ax.errorbar(all_xvalues, all_avg_gr[fk,i], all_gr_stdE[fk,i], fmt = 'none', elinewidth=elinew, capsize=cap_size, \n",
    "                c=cmap2(0.999-(i*0.124)), alpha=(0.7-((i-2)*0.045)))  #    '''\n",
    "5544\n",
    "87ax.set_yscale(\"log\")\n",
    "ax.set_ylim(0.09, 1.0)\n",
    "#ax.set_ylim(-0.03, 1.0)\n",
    "\n",
    "#ax.set_xscale(\"log\")\n",
    "ax.set_xlim(0.085, 6.5) \n",
    "#ax.set_xlim(0.085, 5)\n",
    "#ax.set_xlim(0, 4.8)\n",
    "    \n",
    "title =  data_label #+ \" (normalized CDF)\"   #\"Time = \" + str(time) + \" hrs,\n",
    "ax.set_title(title, fontsize= (font_size))\n",
    "plt.ylabel('g(r)', fontsize=font_size)\n",
    "plt.xlabel('Distance (bead diameters)', fontsize=font_size-1)\n",
    "\n",
    "\n",
    "#leg1 = ax.legend(markerscale=3., fontsize=font_size-6, loc = 'upper right', framealpha= 0, frameon=False)\n",
    "from matplotlib.legend import Legend\n",
    "leg1 = Legend(ax, lines1, time_arr, markerscale=3., fontsize=font_size-6,\n",
    "             loc='upper right', framealpha= 0, frameon=False)\n",
    "leg2 = Legend(ax, lines2, time_arr, markerscale=3., fontsize=font_size-6,\n",
    "             loc='upper right', framealpha= 0, frameon=False)\n",
    "leg3 = Legend(ax, lines3, time_arr, markerscale=3., fontsize=font_size-6,\n",
    "             loc='upper right', framealpha= 0, frameon=False)\n",
    "ax.add_artist(leg1)\n",
    "ax.add_artist(leg2)\n",
    "ax.add_artist(leg3)\n",
    "plt.subplots_adjust(bottom=0.1, left=0.15, right=0.95, top=0.9)\n",
    "ax.axhline((1/np.exp(1)))\n",
    "plt.show()\n",
    "\n",
    "title =  data_label + \" (average g(r))\"   #, transparent=True\n",
    "#fig.savefig(data_saveto+ \"logx Fig3 SIA avg + error + fits \"+title+\".png\", dpi=800, bbox_inches ='tight')\n",
    "#fig.savefig(svg_saveto+ \"logx Fig3 SIA avg + error + fits\"+title+\".svg\", dpi=800, bbox_inches ='tight')\n",
    "#fig.savefig(data_saveto+ \"logy SIA avg + error \"+title+\".png\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "#fig.savefig(svg_saveto+ \"logy SIA avg + error \"+title+\".svg\", dpi=800, bbox_inches ='tight', transparent=True)\n",
    "\n",
    "#fig.savefig(data_saveto+ \"all times SIA avg + error + fits \"+title+\".png\", dpi=800, bbox_inches ='tight')\n",
    "#fig.savefig(svg_saveto+ \"all times SIA avg + error + fits\"+title+\".svg\", dpi=800, bbox_inches ='tight')\n",
    "#fig.savefig(data_saveto+ \"all times SIA avg + error \"+title+\".png\", dpi=800, bbox_inches ='tight')\n",
    "#fig.savefig(svg_saveto+ \"all times SIA avg + error \"+title+\".svg\", dpi=800, bbox_inches ='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "font_size = 20\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "ax.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax.tick_params(axis='both', direction='in', which='minor', length=4, width=2, labelsize=font_size-4)\n",
    "ax2 = ax.twinx()\n",
    "ax2.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax2.tick_params(axis='both', direction='in', which='minor', length=8, width=2, labelsize=font_size-4)\n",
    "\n",
    "this_plot = 'Correlation lengths ($\\mu$m)'  \n",
    "#'mean cluster size ($\\mu$m$^{{2}}$)'  #'clusters found (number)' #'FW at 10% max ($\\mu$m$^{{2}}$)'\n",
    "this_plot_s = \"(FP overlay) \"+ this_plot.split(' ')[0] + \" \" + this_plot.split(' ')[1]\n",
    "\n",
    "end_index = 9\n",
    "y_array = all_median_cl  #all_avg_A[fk,i], all_avg_cl[fk,i]\n",
    "y_stdE = all_cl_stdE   #all_A_stdE[fk,i], all_cl_stdE[fk,i]\n",
    "s_time_array = time_array\n",
    "\n",
    "title = \"SIA -median vals\" \n",
    "ax.set_title(title, fontsize= (font_size))\n",
    "\n",
    "ax.set_ylabel(this_plot, fontsize=font_size-1, labelpad= 12)\n",
    "#ax.tick_params(axis='y', direction='in', which='major', length=8, width=2, labelsize=font_size-6)\n",
    "ax.set_ylim(1.4, 5.1)\n",
    "#ax.set_yscale(\"log\")\n",
    "\n",
    "#ax2.yaxis.set_rotate_label(False)  # disable automatic rotation\n",
    "ax2.set_ylabel('FP', rotation = -90, fontsize=font_size-1, labelpad= 20) #, labelpad= 0, ha='center', va='center'\n",
    "ax2.set_ylim(201, 325)\n",
    "\n",
    "ax.set_xlabel('Time (hours)', fontsize=font_size-1)\n",
    "ax.set_xlim(0, 29)\n",
    "\n",
    "markerSize = 8\n",
    "markerSize2 = 5\n",
    "elinew = 1.5\n",
    "x=1\n",
    "x2=2\n",
    "\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "fk = 0\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "#marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "\n",
    "fk = 2\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "#marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "\n",
    "fk = 3\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "#marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1, left=0.15, right=0.85, top=0.9)             \n",
    "ax.legend(fontsize=font_size-4, framealpha= 0, frameon=False)\n",
    "#ax2.legend(fontsize=font_size-4, framealpha= 0, frameon=False)\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig(data_saveto+this_plot_s+\".jpg\", dpi=800, transparent=True)\n",
    "#fig.savefig(svg_saveto+this_plot_s+\".svg\", dpi=800, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "sim_time = []\n",
    "sim_control = []\n",
    "sim_control_SE = []\n",
    "sim_static = []\n",
    "sim_static_SE = []\n",
    "\n",
    "sim_p1 = []\n",
    "sim_p1_SE = []\n",
    "sim_p2 = []\n",
    "sim_p2_SE = []\n",
    "sim_p3 = []\n",
    "sim_p3_SE = []\n",
    "\n",
    "with open(\"Lauren's CL data (MeanSE).csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC) # change contents to floats\n",
    "    for row in reader: # each row is a list\n",
    "        #print(row[0], row[1], row[2], row[5], row[6], row[7], row[8])\n",
    "        sim_time.append(row[0])\n",
    "        sim_control.append(row[1])\n",
    "        sim_control_SE.append(row[2])\n",
    "        sim_p1.append(row[3])\n",
    "        sim_p1_SE.append(row[4])\n",
    "        sim_p2.append(row[5])\n",
    "        sim_p2_SE.append(row[6])\n",
    "        sim_p3.append(row[7])\n",
    "        sim_p3_SE.append(row[8])\n",
    "        sim_static.append(row[9])\n",
    "        sim_static_SE.append(row[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "font_size = 20\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "ax.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax.tick_params(axis='both', direction='in', which='minor', length=4, width=2, labelsize=font_size-4)\n",
    "ax2 = ax.twinx()\n",
    "ax2.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax2.tick_params(axis='both', direction='in', which='minor', length=8, width=2, labelsize=font_size-4)\n",
    "\n",
    "  \n",
    "#'mean cluster size ($\\mu$m$^{{2}}$)'  #'clusters found (number)' #'FW at 10% max ($\\mu$m$^{{2}}$)'\n",
    "#this_plot_s = \"(FP overlay) EA, AE\"+ this_plot.split(' ')[0] + \" \" + this_plot.split(' ')[1]\n",
    "\n",
    "end_index = 9\n",
    "y_array = all_avg_cl  #all_avg_A[fk,i], all_avg_cl[fk,i], all_median_cl\n",
    "y_stdE = all_cl_stdE   #all_A_stdE[fk,i], all_cl_stdE[fk,i]\n",
    "s_time_array = time_array\n",
    "\n",
    "\n",
    "#ax.tick_params(axis='y', direction='in', which='major', length=8, width=2, labelsize=font_size-6)\n",
    "#ax.set_ylim(1.4, 4.9)\n",
    "#ax.set_yscale(\"log\")\n",
    "\n",
    "#ax2.yaxis.set_rotate_label(False)  # disable automatic rotation\n",
    "ax2.set_ylabel('FP', rotation = -90, fontsize=font_size-1, labelpad= 20) #, labelpad= 0, ha='center', va='center'\n",
    "#ax2.set_ylim(208, 345)\n",
    "\n",
    "ax.set_xlabel('Time (hours)', fontsize=font_size-1)\n",
    "ax.set_xlim(0, 29)\n",
    "\n",
    "markerSize = 8\n",
    "markerSize2 = 8\n",
    "elinew = 1.5\n",
    "xelinew = 1\n",
    "\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "x=2\n",
    "x2=2\n",
    "\n",
    "'''fk = 0\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*2,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*2, yerr = y_stdE[fk]*2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "ax2.plot(FP_time, FP_WTkA_r1, marker, ms=markerSize2, c=cmap, alpha = 0.2, label = \"FP \"+data_label)\n",
    "ax2.plot(FP_time, FP_WTkA_r2, marker, ms=markerSize2, c=cmap, alpha = 0.2)\n",
    "'''\n",
    "\n",
    "max_val = (all_avg_cl[3][0]*2) #(sim_control[0]) #\n",
    "#max_val =  1 #max((all_avg_cl[2] *2)) #max(sim_static) #max((all_avg_cl[2] *2)) \n",
    "y_array = all_avg_cl/max_val\n",
    "y_stdE = all_cl_stdE/max_val\n",
    "\n",
    "max_val2 = (sim_control[0]) #(all_avg_cl[3][0]) #\n",
    "#max_val2 = 1 #max((all_avg_cl[2] *2)) #max(sim_static) #max((all_avg_cl[2] *2)) #\n",
    "print(max_val, max_val2)\n",
    "print(all_avg_cl)\n",
    "\n",
    "\n",
    "fk = 2\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "\n",
    "ax.plot(sim_time, np.array(sim_static)/max_val2, marker, ms=markerSize, c=cmap, mfc='w', label = data_label)\n",
    "ax.errorbar(s_time_array, np.array(sim_static)/max_val2, yerr = np.array(sim_static_SE)/max_val2, \n",
    "            fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, np.array(sim_static)/max_val2, xerr = time_stdE, fmt = 'none', \n",
    "            capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "\n",
    "ax2.plot(FP_time, FP_EA_avg, marker, ms=markerSize2, c=cmap, alpha = 0.2, label = \"FP \"+data_label)\n",
    "\n",
    "fk = 3\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "\n",
    "ax.plot(sim_time, np.array(sim_control)/max_val2, marker, ms=markerSize, c=cmap, mfc='w', label = data_label)\n",
    "ax.errorbar(s_time_array, np.array(sim_control)/max_val2, yerr = np.array(sim_control_SE)/max_val2, \n",
    "            fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, np.array(sim_control)/max_val2, xerr = time_stdE, fmt = 'none', \n",
    "            capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "\n",
    "ax2.plot(FP_time, FP_AE_avg, marker, ms=markerSize2, c=cmap, alpha = 0.2, label = \"FP \"+data_label)\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "#ax.set_ylim(1.4, 5.1)\n",
    "ax2.set_ylim(208, 345)\n",
    "\n",
    "title = \"SIA comparison\" \n",
    "ax.set_title(title, fontsize= (font_size))\n",
    "this_plot = 'exp min normalized CL' #\n",
    "ax.set_ylabel(this_plot, fontsize=font_size-1, labelpad= 12)\n",
    "this_plot_s = \"exp vs sim EA, AE\"+ this_plot\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1, left=0.15, right=0.85, top=0.9)             \n",
    "ax.legend(fontsize=font_size-4, framealpha= 0, frameon=False, loc='upper left')\n",
    "#ax2.legend(fontsize=font_size-4, framealpha= 0, frameon=False)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(data_saveto+this_plot_s+\".jpg\", dpi=800, transparent=True)\n",
    "fig.savefig(svg_saveto+this_plot_s+\".svg\", dpi=800, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "FP_time = []\n",
    "FP_WTkA_r1 = []\n",
    "FP_WTkA_r2 = []\n",
    "FP_EA_r1 = []\n",
    "FP_EA_r2 = []\n",
    "FP_AE_r1 = []\n",
    "FP_AE_r2 = []\n",
    "\n",
    "FP_EA_avg = []\n",
    "FP_AE_avg = []\n",
    "FP_WT_avg = []\n",
    "with open(\"formatted Michelle's FP data.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC) # change contents to floats\n",
    "    for row in reader: # each row is a list\n",
    "        #print(row[0], row[1], row[2], row[5], row[6], row[7], row[8])\n",
    "        FP_time.append(row[0])\n",
    "        FP_WTkA_r1.append(row[1])\n",
    "        FP_WTkA_r2.append(row[2])\n",
    "        FP_EA_r1.append(row[5])\n",
    "        FP_EA_r2.append(row[6])\n",
    "        FP_AE_r1.append(row[7])\n",
    "        FP_AE_r2.append(row[8])\n",
    "        WT_avg = (row[1] + row[2])/2\n",
    "        EA_avg = (row[5] + row[6])/2\n",
    "        AE_avg = (row[7] + row[8])/2\n",
    "        FP_EA_avg.append(EA_avg)\n",
    "        FP_AE_avg.append(AE_avg)\n",
    "        FP_WT_avg.append(WT_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "font_size = 20\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "ax.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax.tick_params(axis='both', direction='in', which='minor', length=4, width=2, labelsize=font_size-4)\n",
    "ax2 = ax.twinx()\n",
    "ax2.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax2.tick_params(axis='both', direction='in', which='minor', length=8, width=2, labelsize=font_size-4)\n",
    "\n",
    "this_plot = 'Median Correlation lengths ($\\mu$m)'  \n",
    "#'mean cluster size ($\\mu$m$^{{2}}$)'  #'clusters found (number)' #'FW at 10% max ($\\mu$m$^{{2}}$)'\n",
    "this_plot_s = \"(FP overlay) EA, AE\"+ this_plot.split(' ')[0] + \" \" + this_plot.split(' ')[1]\n",
    "\n",
    "end_index = 9\n",
    "y_array = all_median_cl  #all_avg_A[fk,i], all_avg_cl[fk,i], all_median_cl\n",
    "y_stdE = all_cl_stdE   #all_A_stdE[fk,i], all_cl_stdE[fk,i]\n",
    "s_time_array = time_array\n",
    "\n",
    "title = \"SIA\" \n",
    "ax.set_title(title, fontsize= (font_size))\n",
    "\n",
    "ax.set_ylabel(this_plot, fontsize=font_size-1, labelpad= 12)\n",
    "#ax.tick_params(axis='y', direction='in', which='major', length=8, width=2, labelsize=font_size-6)\n",
    "#ax.set_ylim(1.4, 4.9)\n",
    "ax.set_ylim(1.4, 5.1)\n",
    "#ax.set_yscale(\"log\")\n",
    "\n",
    "#ax2.yaxis.set_rotate_label(False)  # disable automatic rotation\n",
    "ax2.set_ylabel('FP', rotation = -90, fontsize=font_size-1, labelpad= 20) #, labelpad= 0, ha='center', va='center'\n",
    "ax2.set_ylim(208, 345)\n",
    "\n",
    "ax.set_xlabel('Time (hours)', fontsize=font_size-1)\n",
    "ax.set_xlim(0, 29)\n",
    "\n",
    "markerSize = 8\n",
    "markerSize2 = 8\n",
    "elinew = 1.5\n",
    "xelinew = 1\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "x=1\n",
    "x2=2\n",
    "\n",
    "'''fk = 0\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*2,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*2, yerr = y_stdE[fk]*2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "ax2.plot(FP_time, FP_WTkA_r1, marker, ms=markerSize2, c=cmap, alpha = 0.2, label = \"FP \"+data_label)\n",
    "ax2.plot(FP_time, FP_WTkA_r2, marker, ms=markerSize2, c=cmap, alpha = 0.2)\n",
    "'''\n",
    "\n",
    "fk = 2\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "ax2.plot(FP_time, FP_EA_avg, marker, ms=markerSize2, c=cmap, alpha = 0.2, label = \"FP \"+data_label)\n",
    "\n",
    "fk = 3\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "ax2.plot(FP_time, FP_AE_avg, marker, ms=markerSize2, c=cmap, alpha = 0.2, label = \"FP \"+data_label)\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1, left=0.15, right=0.85, top=0.9)             \n",
    "ax.legend(fontsize=font_size-4, framealpha= 0, frameon=False, loc='upper left')\n",
    "#ax2.legend(fontsize=font_size-4, framealpha= 0, frameon=False)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(data_saveto+this_plot_s+\".jpg\", dpi=800, transparent=True)\n",
    "fig.savefig(svg_saveto+this_plot_s+\".svg\", dpi=800, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "font_size = 20\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "ax.tick_params(axis='both', direction='in', which='major', length=8, width=2, labelsize=font_size-4)\n",
    "ax.tick_params(axis='both', direction='in', which='minor', length=4, width=2, labelsize=font_size-4)\n",
    "\n",
    "this_plot = 'Median Correlation lengths ($\\mu$m)'  \n",
    "#'mean cluster size ($\\mu$m$^{{2}}$)'  #'clusters found (number)' #'FW at 10% max ($\\mu$m$^{{2}}$)'\n",
    "this_plot_s = \"all \"+ this_plot.split(' ')[0] + \" \" + this_plot.split(' ')[1]\n",
    "\n",
    "end_index = 9\n",
    "y_array = all_median_cl  #all_avg_A[fk,i], all_avg_cl[fk,i], all_median_cl\n",
    "y_stdE = all_cl_stdE   #all_A_stdE[fk,i], all_cl_stdE[fk,i]\n",
    "s_time_array = time_array\n",
    "\n",
    "title = \"SIA\" \n",
    "ax.set_title(title, fontsize= (font_size))\n",
    "\n",
    "ax.set_ylabel(this_plot, fontsize=font_size-1, labelpad= 12)\n",
    "#ax.tick_params(axis='y', direction='in', which='major', length=8, width=2, labelsize=font_size-6)\n",
    "#ax.set_ylim(1.4, 4.9)\n",
    "ax.set_ylim(1.4, 5.1)\n",
    "#ax.set_yscale(\"log\")\n",
    "\n",
    "ax.set_xlabel('Time (hours)', fontsize=font_size-1)\n",
    "ax.set_xlim(0, 29)\n",
    "\n",
    "markerSize = 8\n",
    "markerSize2 = 8\n",
    "elinew = 1.5\n",
    "xelinew = 1\n",
    "\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "x=1\n",
    "x2=2\n",
    "\n",
    "fk = 0\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "\n",
    "fk = 2\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "\n",
    "fk = 3\n",
    "marker, cmap, cmap2, data_label = select_cmap(fk)\n",
    "marker = '--'+marker\n",
    "ax.plot(s_time_array, y_array[fk]*x,marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, yerr = y_stdE[fk]*x2, fmt = 'none', capthick=elinew, ecolor=cmap, capsize=10)\n",
    "ax.errorbar(s_time_array, y_array[fk]*x, xerr = time_stdE, fmt = 'none', capthick=xelinew, ecolor=cmap, capsize=18)\n",
    "###########################################################################\n",
    "###########################################################################\n",
    "\n",
    "plt.subplots_adjust(bottom=0.1, left=0.15, right=0.95, top=0.9)             \n",
    "ax.legend(fontsize=font_size-4, framealpha= 0, frameon=False, loc='upper left')\n",
    "#ax2.legend(fontsize=font_size-4, framealpha= 0, frameon=False)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(data_saveto+this_plot_s+\".jpg\", dpi=800, transparent=True)\n",
    "fig.savefig(svg_saveto+this_plot_s+\".svg\", dpi=800, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_array = np.zeros((num_times,18))\n",
    "A_array = np.zeros((num_times,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk = 3\n",
    "all_A_vals, all_cl_vals, data_label = select_results(fk)\n",
    "for i in range(num_times):\n",
    "    for j in range(18):\n",
    "        cl_array[i][j] = (all_cl_vals[i][j])*2\n",
    "#print(cl_array[0])\n",
    "new_cl_array = np.swapaxes(cl_array,0,1)\n",
    "#print(new_array)\n",
    "\n",
    "for i in range(num_times):\n",
    "    for j in range(18):\n",
    "        A_array[i][j] = (all_A_vals[i][j])*2\n",
    "#print(cl_array[0])\n",
    "new_A_array = np.swapaxes(A_array,0,1)\n",
    "print(new_A_array.shape)\n",
    "print(new_cl_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_file = \"New SIA results \"+data_label+\".csv\"   \n",
    "header = []\n",
    "np.savetxt(data_saveto+csv_data_file, header, fmt=\"%s\", delimiter=',')\n",
    "with open(data_saveto+csv_data_file,'a', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow([data_label])\n",
    "    writer.writerow([\"A values\"])\n",
    "    writer.writerow([\"1\", \"4\", \"7\", \"10\", \"14\", \"18\", \"21\", \"25\", \"28\"])\n",
    "    for i in range(18):\n",
    "        writer.writerow(new_A_array[i])\n",
    "    writer.writerow([''])\n",
    "    writer.writerow([''])\n",
    "    writer.writerow([\"correlation lengths\"])\n",
    "    writer.writerow([\"1\", \"4\", \"7\", \"10\", \"14\", \"18\", \"21\", \"25\", \"28\"])\n",
    "    for i in range(18):\n",
    "        writer.writerow(new_cl_array[i])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "font_size = 20\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "ax.tick_params(axis='both', direction='in', which='major', length=6, width=2, labelsize=font_size-6)\n",
    "ax.tick_params(axis='both', direction='in', which='minor', length=3, width=2, labelsize=font_size-6)\n",
    "\n",
    "this_plot = 'Correlation lengths (bead diameters)'  \n",
    "#'mean cluster size ($\\mu$m$^{{2}}$)'  #'clusters found (number)' #'FW at 10% max ($\\mu$m$^{{2}}$)'\n",
    "this_plot_s = \"0-28_\"+this_plot\n",
    "\n",
    "end_index = 9\n",
    "y_array = all_avg_cl  #all_avg_A[fk,i], all_avg_cl[fk,i]\n",
    "y_stdE = all_cl_stdE   #all_A_stdE[fk,i], all_cl_stdE[fk,i]\n",
    "s_time_array = time_array\n",
    "\n",
    "#ax.set_ylim(2, 21)\n",
    "ax.set_xlim(0, 29)\n",
    "marker = '--d'\n",
    "markerSize = 8\n",
    "font_size = 16\n",
    "cmap_num = 0.6\n",
    "#threshold_details = \" (clusters >= \"+str(beads_per_cluster)+\" beads)\"\n",
    "title = \"SIA\" \n",
    "\n",
    "ax.set_title(title, fontsize= (font_size))\n",
    "plt.ylabel(this_plot, fontsize=font_size)\n",
    "plt.xlabel('Time (hours)', fontsize=font_size)\n",
    "ax.ticklabel_format(style='plain')\n",
    "\n",
    "fk = 3\n",
    "marker, cmap, all_t_clusters, data_label = select_cmap(fk)\n",
    "for i in range(num_times):\n",
    "    for j in range(18):\n",
    "        array[i][j] = WTkA_all_t_cl_vals[i][j]\n",
    "new_array = np.swapaxes(array,0,1)\n",
    "ax.boxplot(new_array[0], marker)\n",
    "\n",
    "'''fk = 3\n",
    "cmap, all_t_clusters, data_label = select_cmap(fk)\n",
    "ax.plot(s_time_array, y_array[fk],marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk], yerr = y_stdE[fk], fmt = 'none', ecolor=cmap, capsize=10)\n",
    "fk = 2\n",
    "cmap, all_t_clusters, data_label = select_cmap(fk)\n",
    "ax.plot(s_time_array, y_array[fk],marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk], yerr = y_stdE[fk], fmt = 'none', ecolor=cmap, capsize=10)\n",
    "fk = 0\n",
    "cmap, all_t_clusters, data_label = select_cmap(fk)\n",
    "ax.plot(s_time_array, y_array[fk],marker, ms=markerSize, c=cmap, label = data_label)\n",
    "ax.errorbar(s_time_array, y_array[fk], yerr = y_stdE[fk], fmt = 'none', ecolor=cmap, capsize=10)'''\n",
    "\n",
    "plt.show()\n",
    "ax.legend(fontsize=font_size-2, framealpha= 0, frameon=False)\n",
    "#threshold_details = \" (clusters AL \"+str(beads_per_cluster)+\" beads, bsize= \"+str(block_size)+\", offset= \"+str(offset_val)+\")\"\n",
    "#fig.savefig(data_saveto+this_plot_s+threshold_details+\".jpg\", dpi=800)\n",
    "#fig.savefig(svg_saveto+this_plot_s+threshold_details+\".svg\", dpi=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we fit the SIA curves to a single exponential, fit equation: y = e^(-x/L1) + A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(figsize=(fig_size))\n",
    "ax.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "markerSize = 6\n",
    "\n",
    "### Set up dictionary (\"results_dict\") and more empty arrays to save results in\n",
    "results_dict = {}\n",
    "results_dict[\"time array\"] = time_array\n",
    "\n",
    "r1_params = [0.0] * arr_length\n",
    "r2_params = [0.0] * arr_length\n",
    "r3_params = [0.0] * arr_length\n",
    "\n",
    "### FIT PARAMETERS: adjust these to change the range for fitting attempts \n",
    "fit_start = 0\n",
    "fit_lim = -1 \n",
    "retry_num = 10 #retry_num is the number of fitting attempts to try before moving on, not very relevant to single exp fits\n",
    "x_fit_lim = all_xvalues[fit_lim]\n",
    "print(\"first x-value= %5.3f, start fits at %5.3f; fit until xlim = %5.3f\" %(all_xvalues[1], all_xvalues[fit_start], x_fit_lim))\n",
    "print(\"Fits:\")\n",
    "\n",
    "for i in range(arr_length):     \n",
    "    full_filename = files[i]\n",
    "    time = str(time_array[i]) + \" hrs\" #\"time \"+(full_filename.split('\\\\')[-1])[12:-4]\n",
    "\n",
    "### load and plot the 3 original SIA curves corresponding to 3 tiff files associated with each time point \n",
    "    r1_y_array = r1_corr_rad_array[i]\n",
    "    r2_y_array = r2_corr_rad_array[i]\n",
    "    r3_y_array = r3_corr_rad_array[i]\n",
    "    plt.semilogx(all_xvalues,r1_y_array,'.',ms=markerSize,c=cmap(0.9-(i/cmap_num)),label=time)\n",
    "    #plt.plot(all_xvalues,r2_y_array,'.',ms=markerSize,c=cmap(0.9-(i/cmap_num)))\n",
    "    plt.plot(all_xvalues,r3_y_array,'.',ms=markerSize,c=cmap(0.9-(i/cmap_num)))\n",
    "    \n",
    "### x_fit_values has the same range as \"all_xvalues\", but includes more values to produce better fits\n",
    "    x_fit_values = np.linspace(all_xvalues[fit_start], all_xvalues[fit_lim], 1000) \n",
    "\n",
    "### the \"curve_fit\" function from scipy does the initial fitting attempt\n",
    "    r1_popt, r1_pcov = curve_fit(single_exponential, all_xvalues[fit_start:fit_lim], r1_y_array[fit_start:fit_lim])\n",
    "    r2_popt, r2_pcov = curve_fit(single_exponential, all_xvalues[fit_start:fit_lim], r2_y_array[fit_start:fit_lim])\n",
    "    r3_popt, r3_pcov = curve_fit(single_exponential, all_xvalues[fit_start:fit_lim], r3_y_array[fit_start:fit_lim])\n",
    "    print(time+\"-- \"+'r1 fit: A=%5.3f, l1=%5.3f' % tuple(r1_popt))\n",
    "    print(time+\"-- \"+'r2 fit: A=%5.3f, l1=%5.3f' % tuple(r2_popt))\n",
    "    print(time+\"-- \"+'r3 fit: A=%5.3f, l1=%5.3f' % tuple(r3_popt))\n",
    "    r1_A, r1_cl = tuple(r1_popt)\n",
    "    r2_A, r2_cl = tuple(r2_popt)\n",
    "    r3_A, r3_cl = tuple(r3_popt)\n",
    "    \n",
    "### the \"check fits\" function re-runs \"curve_fit\" with a slightly smaller range until the fit parameters meet our criteria\n",
    "### specified in the \"check fits\" function, our fit parameters criteria was more relevant for double exponential fits\n",
    "### (most single exponential fits work first try)\n",
    "    #r1_A, r1_cl = check_fits(r1_A, r1_cl, r1_y_array, retry_num)\n",
    "    #r2_A, r2_cl = check_fits(r2_A, r2_cl, r2_y_array, retry_num)\n",
    "    #r3_A, r3_cl = check_fits(r3_A, r3_cl, r3_y_array, retry_num)\n",
    "    \n",
    "### generate and plot curves based on the fits \n",
    "    r1_fit_values = single_exponential(x_fit_values, *r1_popt)\n",
    "    r2_fit_values = single_exponential(x_fit_values, *r2_popt)\n",
    "    r3_fit_values = single_exponential(x_fit_values, *r3_popt)\n",
    "    plt.plot(x_fit_values, r1_fit_values,'--',c=cmap(0.99-(i/cmap_num)))\n",
    "    #plt.plot(x_fit_values, r2_fit_values,'--',c=cmap(0.99-(i/cmap_num)))\n",
    "    plt.plot(x_fit_values, r3_fit_values,'--',c=cmap(0.99-(i/cmap_num)))\n",
    "    \n",
    "### saving all data & results to results dictionary \n",
    "    results_dict[time] = {} #creates sub dictionary (within results_dict) for each frame analyzed \n",
    "    results_dict[time][\"x vals\"] = all_xvalues\n",
    "    results_dict[time][\"r1 y vals\"] = r1_y_array\n",
    "    results_dict[time][\"r2 y vals\"] = r2_y_array\n",
    "    results_dict[time][\"r3 y vals\"] = r3_y_array\n",
    "    \n",
    "    results_dict[time][\"avg y vals\"] = mean_corr_rad_array[i]\n",
    "    results_dict[time][\"avg y error\"] = std_error_array[i]\n",
    "    \n",
    "    results_dict[time][\"x fit vals\"] = x_fit_values\n",
    "    results_dict[time][\"r1 fit vals\"] = r1_fit_values\n",
    "    results_dict[time][\"r2 fit vals\"] = r2_fit_values\n",
    "    results_dict[time][\"r3 fit vals\"] = r3_fit_values\n",
    "    \n",
    "    results_dict[time][\"r1 fit params\"] = [r1_A, r1_cl]\n",
    "    results_dict[time][\"r2 fit params\"] = [r2_A, r2_cl]\n",
    "    results_dict[time][\"r3 fit params\"] = [r3_A, r3_cl]\n",
    "    \n",
    "    r1_params[i] = (r1_A, r1_cl)\n",
    "    r2_params[i] = (r2_A, r2_cl) \n",
    "    r3_params[i] = (r3_A, r3_cl)\n",
    "    #print(\"br_yarray[0] = %5.3f, br_yarray[1] = %5.3f, br_fit_values[0] = %5.3f, br_fit_values[1] = %5.3f\" %(br_y_array[0], \n",
    "      #                                                                                                   br_y_array[1],\n",
    "       #                                                                                                  br_fit_values[0], \n",
    "                #                                                                                         br_fit_values[1]))\n",
    "print(r2_params)\n",
    "print(r3_params)\n",
    "plt.xlabel(\"Distance (scaled by bead diameter)\",fontsize=font_size)\n",
    "plt.ylabel(\"Autocorrelation\",fontsize=font_size)\n",
    "ax.legend(loc=0, markerscale=2.,fontsize=font_size-3)\n",
    "#plt.ylim(0.1, 1.1)\n",
    "#plt.ylim(0.006, 1.01)\n",
    "#plt.xlim(0, 5)\n",
    "#plt.xlim(0, all_xvalues[-10]+5)\n",
    "plt.xlim(0, all_xvalues[fit_lim]+5) ## (0.091 um/px) * (1440 px) = 131.04 um --> =size of image x-axis in microns\n",
    "str_equation = True\n",
    "equation = single_exponential(x_fit_values, *r1_popt)\n",
    "ax.text(1.2,0.95, \"fit equation: \" + equation, fontsize=font_size-2)\n",
    "str_equation = False\n",
    "\n",
    "title_plus = title + \"; fits range (%5.3f um, %5.3f um)\" %(all_xvalues[fit_start], x_fit_lim)\n",
    "title = frame_names[key]\n",
    "plt.title(title, fontsize=font_size -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###save figure\n",
    "fig.savefig(plot_saveto+exp+\" threshold SIA fits for \"+title_plus+\".jpg\", dpi=dpi_num)\n",
    "###save dictionary results \n",
    "file_to_write = open(plot_saveto+exp+\" threshold SIA results for \"+title+\".p\", \"wb\")\n",
    "#file_to_write = open(plot_saveto+ \"SIA results for \"+title_plus+\".p\", \"wb\")\n",
    "pickle.dump(results_dict, file_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine and plot the results of fitting SIA curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "array_len = len(r1_params)\n",
    "### set up empty arrays\n",
    "all_cl = np.zeros((total_rows,array_len))\n",
    "avg_cl = np.empty(array_len)\n",
    "stderror_cl = np.empty(array_len)\n",
    "\n",
    "### find average values and std. error for correlation lengths (lc) based on the fits \n",
    "for i in range(array_len):\n",
    "    all_cl[0,i] = r1_params[i][1]\n",
    "    all_cl[1,i] = r2_params[i][1]\n",
    "    all_cl[2,i] = r3_params[i][1]\n",
    "avg_cl = all_cl.mean(axis=0)\n",
    "stderror_cl = (all_cl.std(axis=0))/np.sqrt(total_rows)   #\n",
    "print(all_cl)\n",
    "#print(all_cl.mean(axis=0))\n",
    "#print(stderror_cl)\n",
    "\n",
    "### plot average values and std. error for correlation lengths\n",
    "fig, ax = plt.subplots(figsize=(fig_size))\n",
    "markerSize = 8\n",
    "\n",
    "for i in range(int(len(time_array))):\n",
    "    plt.plot(time_array[i], avg_cl[i],'s', ms=markerSize, c=cmap(0.9-(i/cmap_num)))\n",
    "    ax.errorbar(time_array[i], avg_cl[i], yerr = stderror_cl[i], fmt = 'none', \n",
    "                ecolor=cmap(0.9-(i/cmap_num)), capsize=10)\n",
    "    \n",
    "plt.xlabel(\"Time (hrs after adding KaiC)\",fontsize=font_size)\n",
    "plt.ylabel(\"Correlation length ($\\mu$m)\",fontsize=font_size)\n",
    "ax.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "plt.ylim(1,6)\n",
    "#title_plus = title + \"; n fits range (%5.3f um, %5.3f um)\" %(all_xvalues[fit_start], x_fit_lim)\n",
    "plt.title(title_plus, fontsize=font_size -4)\n",
    "plt.show()\n",
    "\n",
    "### save plot\n",
    "fig.savefig(plot_saveto+exp+\" threshold correlation lengths for \"+title_plus+\".jpg\", dpi=dpi_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_len = len(r1_params)\n",
    "### set up empty arrays\n",
    "all_A = np.zeros((total_rows,array_len))\n",
    "avg_A = np.empty(array_len)\n",
    "stderror_A = np.empty(array_len)\n",
    "\n",
    "### find average values and std. error for correlation lengths (lc) based on the fits \n",
    "for i in range(array_len):\n",
    "    all_A[0,i] = r1_params[i][0]\n",
    "    all_A[1,i] = r2_params[i][0]\n",
    "    all_A[2,i] = r3_params[i][0]\n",
    "avg_A = all_A.mean(axis=0)\n",
    "stderror_A = (all_A.std(axis=0))/np.sqrt(total_rows)   #\n",
    "print(all_A)\n",
    "#print(all_cl.mean(axis=0))\n",
    "#print(stderror_cl)\n",
    "\n",
    "### plot average values and std. error for correlation lengths\n",
    "fig, ax = plt.subplots(figsize=(fig_size))\n",
    "markerSize = 8\n",
    "\n",
    "for i in range(int(len(time_array))):\n",
    "    plt.plot(time_array[i], avg_A[i],'s', ms=markerSize, c=cmap(0.9-(i/cmap_num)))\n",
    "    ax.errorbar(time_array[i], avg_A[i], yerr = stderror_A[i], fmt = 'none', \n",
    "                ecolor=cmap(0.9-(i/cmap_num)), capsize=10)\n",
    "    \n",
    "plt.xlabel(\"time (hrs after adding KaiC)\",fontsize=font_size)\n",
    "plt.ylabel(\"offset parameter (... + A) value (unitless)\",fontsize=font_size)\n",
    "ax.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "#plt.ylim(0.001,0.04)\n",
    "#title_plus = title + \"; n fits range (%5.3f um, %5.3f um)\" %(all_xvalues[fit_start], x_fit_lim)\n",
    "plt.title(title_plus, fontsize=font_size -4)\n",
    "plt.show()\n",
    "\n",
    "### save plot\n",
    "fig.savefig(plot_saveto+exp+\" threshold A values for \"+title_plus+\".jpg\", dpi=dpi_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all results to 3 seperate CSV files --> use for plotting in origin later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### first CSV file: save fit parameters (coefficient 'A' and correlation length 'L1'), and avg autocorrelation plateau values\n",
    "csv_data_file = exp+\" results- threshold SIA fit parameters.csv\"\n",
    "data_file_exists = os.path.isfile(plot_saveto+csv_data_file)\n",
    "if data_file_exists:\n",
    "    print(csv_data_file + \" already exists.\")\n",
    "    with open(plot_saveto+csv_data_file,'a', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow([title_plus])\n",
    "        writer.writerow(['time (hrs)','','r1 A','r2 A','r3 A','','avg A', 'A std E','','','r1 cL','r2 cL','r3 cL','', \n",
    "                         'avg cL', 'cL std E'])\n",
    "        for i in range(len(time_array)):\n",
    "            writer.writerow([time_array[i],'', r1_params[i][0], r2_params[i][0], r3_params[i][0],'', avg_A[i], stderror_A[i],'','',\n",
    "                             r1_params[i][1], r2_params[i][1], r3_params[i][1],'', avg_cl[i], stderror_cl[i]])\n",
    "        writer.writerow([''])\n",
    "    f.close()\n",
    "    print(\"Results appended to \"+ csv_data_file)\n",
    "else:\n",
    "    print(csv_data_file + \" does NOT exist.\")\n",
    "    header = []\n",
    "    np.savetxt(plot_saveto+csv_data_file, header, fmt=\"%s\", delimiter=',')\n",
    "    with open(plot_saveto+csv_data_file,'a', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow([title_plus])\n",
    "        writer.writerow(['time (hrs)','','r1 A','r2 A','r3 A','','avg A', 'A std E','','','r1 cL','r2 cL','r3 cL','', \n",
    "                         'avg cL', 'cL std E'])\n",
    "        for i in range(len(time_array)):\n",
    "            writer.writerow([time_array[i],'', r1_params[i][0], r2_params[i][0], r3_params[i][0],'', avg_A[i], stderror_A[i],'','',\n",
    "                             r1_params[i][1], r2_params[i][1], r3_params[i][1],'', avg_cl[i], stderror_cl[i]])\n",
    "        writer.writerow([''])\n",
    "    f.close()\n",
    "    print(\"New csv created, results appended to \"+ csv_data_file)\n",
    "\n",
    "### BOX PLOTS CSV file: save fit parameters (coefficient 'A' and correlation length 'L1'), and avg autocorrelation plateau values\n",
    "csv_data_file = exp+\" Box Plot results- threshold SIA fit parameters.csv\"\n",
    "data_file_exists = os.path.isfile(plot_saveto+csv_data_file)\n",
    "if data_file_exists:\n",
    "    print(csv_data_file + \" already exists.\")\n",
    "    with open(plot_saveto+csv_data_file,'a', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow([title_plus])\n",
    "        writer.writerow(['','A values','','','','','','','','','','','','correlation length'])\n",
    "        writer.writerow(['time (hrs)',time_array[0],time_array[1],time_array[2],time_array[3],time_array[4],time_array[5],\n",
    "                         time_array[6],time_array[7],time_array[8],'','',\n",
    "                         'time (hrs)',time_array[0],time_array[1],time_array[2],time_array[3],time_array[4],time_array[5],\n",
    "                         time_array[6],time_array[7],time_array[8],'','',])\n",
    "        \n",
    "        writer.writerow(['row1', r1_params[0][0], r1_params[1][0], r1_params[2][0], r1_params[3][0], r1_params[4][0],\n",
    "                         r1_params[5][0], r1_params[6][0], r1_params[7][0], r1_params[8][0],'','',\n",
    "                         'row1', r1_params[0][1], r1_params[1][1], r1_params[2][1], r1_params[3][1], r1_params[4][1],\n",
    "                         r1_params[5][1], r1_params[6][1], r1_params[7][1], r1_params[8][1],'','',])\n",
    "        \n",
    "        writer.writerow(['row2', r2_params[0][0], r2_params[1][0], r2_params[2][0], r2_params[3][0], r2_params[4][0],\n",
    "                         r2_params[5][0], r2_params[6][0], r2_params[7][0], r2_params[8][0],'','',\n",
    "                         'row2', r2_params[0][1], r2_params[1][1], r2_params[2][1], r2_params[3][1], r2_params[4][1],\n",
    "                         r2_params[5][1], r2_params[6][1], r2_params[7][1], r2_params[8][1],'','',])\n",
    "        \n",
    "        writer.writerow(['row3', r3_params[0][0], r3_params[1][0], r3_params[2][0], r3_params[3][0], r3_params[4][0],\n",
    "                         r3_params[5][0], r3_params[6][0], r3_params[7][0], r3_params[8][0],'','',\n",
    "                         'row3', r3_params[0][1], r3_params[1][1], r3_params[2][1], r3_params[3][1], r3_params[4][1],\n",
    "                         r3_params[5][1], r3_params[6][1], r3_params[7][1], r3_params[8][1],'','',])\n",
    "        writer.writerow([''])\n",
    "        writer.writerow([''])\n",
    "    f.close()\n",
    "    print(\"Results appended to \"+ csv_data_file)\n",
    "else:\n",
    "    print(csv_data_file + \" does NOT exist.\")\n",
    "    header = []\n",
    "    np.savetxt(plot_saveto+csv_data_file, header, fmt=\"%s\", delimiter=',')\n",
    "    with open(plot_saveto+csv_data_file,'a', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        writer.writerow([title_plus])\n",
    "        writer.writerow(['','A values','','','','','','','','','','','','correlation length'])\n",
    "        writer.writerow(['time (hrs)',time_array[0],time_array[1],time_array[2],time_array[3],time_array[4],time_array[5],\n",
    "                         time_array[6],time_array[7],time_array[8],'','',\n",
    "                         'time (hrs)',time_array[0],time_array[1],time_array[2],time_array[3],time_array[4],time_array[5],\n",
    "                         time_array[6],time_array[7],time_array[8],'','',])\n",
    "        \n",
    "        writer.writerow(['row1', r1_params[0][0], r1_params[1][0], r1_params[2][0], r1_params[3][0], r1_params[4][0],\n",
    "                         r1_params[5][0], r1_params[6][0], r1_params[7][0], r1_params[8][0],'','',\n",
    "                         'row1', r1_params[0][1], r1_params[1][1], r1_params[2][1], r1_params[3][1], r1_params[4][1],\n",
    "                         r1_params[5][1], r1_params[6][1], r1_params[7][1], r1_params[8][1],'','',])\n",
    "        \n",
    "        writer.writerow(['row2', r2_params[0][0], r2_params[1][0], r2_params[2][0], r2_params[3][0], r2_params[4][0],\n",
    "                         r2_params[5][0], r2_params[6][0], r2_params[7][0], r2_params[8][0],'','',\n",
    "                         'row2', r2_params[0][1], r2_params[1][1], r2_params[2][1], r2_params[3][1], r2_params[4][1],\n",
    "                         r2_params[5][1], r2_params[6][1], r2_params[7][1], r2_params[8][1],'','',])\n",
    "        \n",
    "        writer.writerow(['row3', r3_params[0][0], r3_params[1][0], r3_params[2][0], r3_params[3][0], r3_params[4][0],\n",
    "                         r3_params[5][0], r3_params[6][0], r3_params[7][0], r3_params[8][0],'','',\n",
    "                         'row3', r3_params[0][1], r3_params[1][1], r3_params[2][1], r3_params[3][1], r3_params[4][1],\n",
    "                         r3_params[5][1], r3_params[6][1], r3_params[7][1], r3_params[8][1],'','',])\n",
    "        writer.writerow([''])\n",
    "        writer.writerow([''])\n",
    "    f.close()\n",
    "    print(\"New csv created, results appended to \"+ csv_data_file)\n",
    "    \n",
    "### second CSV file: save raw data (x and y values) of each original SIA curve (3 curves for each time point)\n",
    "csv_data_file = exp+\" results- threshold SIA raw data\"+title+\".csv\"   \n",
    "header = []\n",
    "np.savetxt(plot_saveto+csv_data_file, header, fmt=\"%s\", delimiter=',')\n",
    "with open(plot_saveto+csv_data_file,'a', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for j in range(len(time_array)):\n",
    "        time = str(time_array[j]) + ' hrs'\n",
    "        writer.writerow([time])\n",
    "        writer.writerow(['x vals','','r1 y vals','r2 y vals','r3 y vals','','avg y vals','avg y error'])\n",
    "        for i in range(len(results_dict[time]['x vals'])):\n",
    "            writer.writerow([results_dict[time]['x vals'][i],'', results_dict[time]['r1 y vals'][i],\n",
    "                            results_dict[time]['r2 y vals'][i], results_dict[time]['r3 y vals'][i],'',\n",
    "                            results_dict[time]['avg y vals'][i], results_dict[time]['avg y error'][i]])\n",
    "        writer.writerow([''])\n",
    "        writer.writerow([''])\n",
    "f.close()\n",
    "\n",
    "### third CSV file: save the raw data (x and y values) of each fit to each original SIA curve (3 curves for each time point)\n",
    "csv_data_file = exp+\" results- threshold SIA fits data\"+title+\".csv\"\n",
    "header = []\n",
    "np.savetxt(plot_saveto+csv_data_file, header, fmt=\"%s\", delimiter=',')\n",
    "with open(plot_saveto+csv_data_file,'a', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for j in range(len(time_array)):\n",
    "        time = str(time_array[j]) + ' hrs'\n",
    "        writer.writerow([time])\n",
    "        writer.writerow(['x fit vals','','r1 fit vals','r2 fit vals','r3 fit vals'])\n",
    "        for i in range(len(results_dict[time]['x fit vals'])):\n",
    "            writer.writerow([results_dict[time]['x fit vals'][i], '', results_dict[time]['r1 fit vals'][i],\n",
    "                            results_dict[time]['r2 fit vals'][i], results_dict[time]['r3 fit vals'][i]])\n",
    "        writer.writerow([''])\n",
    "        writer.writerow([''])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First round complete! \n",
    "## Now we can scroll back to the top and change the 'key' variable to run through the next frame (i.e. condition) of all tiff files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
